<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AutoGen小白篇(Windows) | star徐的博客</title><meta name=keywords content="AutoGen,agent,大模型,工作流,worker"><meta name=description content="AutoGen小白篇(Windows)
1. 什么是 AutoGen？它解决了什么痛点？
AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性
从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。
核心定义
它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个协作平台。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。
解决的痛点

单打独斗的局限性：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。
上下文管理难：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。
工具集成繁琐：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。
扩展性差：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。

2. 核心特点与架构组成 (核心分析)
AutoGen v0.4 的设计理念是 “异步、事件驱动、分布式”。
2.1 架构分层
AutoGen 的架构是分层的、可扩展的，基于发布-订阅模型。核心组件包括：

代理（Agents）：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。
事件（Events）：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。
主题（Topics）：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。
服务（Services）：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。
后端选项：内存、Python 服务、Microsoft Orleans（分布式演员系统）。

整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。"><meta name=author content="您的姓名"><link rel=canonical href=http://ljj1992.fun/posts/autogen/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=http://ljj1992.fun/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://ljj1992.fun/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://ljj1992.fun/favicon-32x32.png><link rel=apple-touch-icon href=http://ljj1992.fun/apple-touch-icon.png><link rel=mask-icon href=http://ljj1992.fun/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://ljj1992.fun/posts/autogen/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="http://ljj1992.fun/posts/autogen/"><meta property="og:site_name" content="star徐的博客"><meta property="og:title" content="AutoGen小白篇(Windows)"><meta property="og:description" content="AutoGen小白篇(Windows) 1. 什么是 AutoGen？它解决了什么痛点？ AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性
从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。
核心定义 它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个协作平台。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。
解决的痛点 单打独斗的局限性：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。 上下文管理难：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。 工具集成繁琐：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。 扩展性差：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。 2. 核心特点与架构组成 (核心分析) AutoGen v0.4 的设计理念是 “异步、事件驱动、分布式”。
2.1 架构分层 AutoGen 的架构是分层的、可扩展的，基于发布-订阅模型。核心组件包括： 代理（Agents）：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。 事件（Events）：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。 主题（Topics）：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。 服务（Services）：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。 后端选项：内存、Python 服务、Microsoft Orleans（分布式演员系统）。 整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-22T12:35:00+08:00"><meta property="article:modified_time" content="2025-11-22T12:35:00+08:00"><meta property="article:tag" content="AutoGen"><meta property="article:tag" content="Agent"><meta property="article:tag" content="大模型"><meta property="article:tag" content="工作流"><meta property="article:tag" content="Worker"><meta name=twitter:card content="summary"><meta name=twitter:title content="AutoGen小白篇(Windows)"><meta name=twitter:description content="AutoGen小白篇(Windows)
1. 什么是 AutoGen？它解决了什么痛点？
AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性
从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。
核心定义
它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个协作平台。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。
解决的痛点

单打独斗的局限性：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。
上下文管理难：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。
工具集成繁琐：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。
扩展性差：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。

2. 核心特点与架构组成 (核心分析)
AutoGen v0.4 的设计理念是 “异步、事件驱动、分布式”。
2.1 架构分层
AutoGen 的架构是分层的、可扩展的，基于发布-订阅模型。核心组件包括：

代理（Agents）：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。
事件（Events）：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。
主题（Topics）：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。
服务（Services）：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。
后端选项：内存、Python 服务、Microsoft Orleans（分布式演员系统）。

整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://ljj1992.fun/posts/"},{"@type":"ListItem","position":2,"name":"AutoGen小白篇(Windows)","item":"http://ljj1992.fun/posts/autogen/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AutoGen小白篇(Windows)","name":"AutoGen小白篇(Windows)","description":"AutoGen小白篇(Windows) 1. 什么是 AutoGen？它解决了什么痛点？ AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性\n从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。\n核心定义 它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个协作平台。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。\n解决的痛点 单打独斗的局限性：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。 上下文管理难：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。 工具集成繁琐：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。 扩展性差：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。 2. 核心特点与架构组成 (核心分析) AutoGen v0.4 的设计理念是 “异步、事件驱动、分布式”。\n2.1 架构分层 AutoGen 的架构是分层的、可扩展的，基于发布-订阅模型。核心组件包括： 代理（Agents）：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。 事件（Events）：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。 主题（Topics）：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。 服务（Services）：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。 后端选项：内存、Python 服务、Microsoft Orleans（分布式演员系统）。 整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。\n","keywords":["AutoGen","agent","大模型","工作流","worker"],"articleBody":"AutoGen小白篇(Windows) 1. 什么是 AutoGen？它解决了什么痛点？ AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性\n从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。\n核心定义 它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个协作平台。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。\n解决的痛点 单打独斗的局限性：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。 上下文管理难：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。 工具集成繁琐：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。 扩展性差：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。 2. 核心特点与架构组成 (核心分析) AutoGen v0.4 的设计理念是 “异步、事件驱动、分布式”。\n2.1 架构分层 AutoGen 的架构是分层的、可扩展的，基于发布-订阅模型。核心组件包括： 代理（Agents）：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。 事件（Events）：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。 主题（Topics）：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。 服务（Services）：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。 后端选项：内存、Python 服务、Microsoft Orleans（分布式演员系统）。 整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。\n对AutoGen的大白话解释 AutoGen 就像一个“AI 客服呼叫中心”：\n代理 = 每一个坐席客服 事件 = 客户打进来的电话（带着“谁打的、什么事”） 主题 = 呼叫中心的分机号（比如“技术支持 8001”“退货 8002”） 服务 = 后勤部门（总机、调度室、档案室、数据库） 整个系统靠“电话铃响了谁接”而不是“你去叫张三来接电话”来运转，这就是发布-订阅的本质。 下面用一个真实的呼叫中心来彻底讲明白 AutoGen 的每一层。\n1. 代理（Agents）—— 真正干活的客服小哥哥小姐姐 大白话：每个代理就是一个会用大模型思考的“智能员工”。你给他发消息，他就能看、思考、回话、打电话（调用工具）、写笔记（改内存）。 原理：他们不主动找活干，只听电话铃（事件）。铃声一响，匹配到自己的分机号，就开始处理。 真实例子 写手代理：专门写文章 代码代理：专门写代码 浏览网页代理：专门上网查东西 审查代理：专门挑毛病 2. 事件（Events）—— 客户打进来的每一通电话 大白话：一张标准工单，上面写清楚： “谁打的（source）” + “什么事（type）” + “具体内容（data）” + “工单编号（id）” 这就是 CloudEvents 格式，全国客服中心都认这个标准。 真实例子： 你问：“帮我写一个神经网络” → 系统立刻生成一张工单： type = “用户提问” source = “你” data = “帮我写一个神经网络” id = “uuid-12345” 3. 主题（Topics）—— 呼叫中心的分机号和转接规则 大白话：就像你拨打客服电话： 技术问题按1 → 转到技术组 退货按2 → 转到售后组 代理提前登记“我能接1号分机”，电话一来自动转过去。 两个关键概念 type（主题类型）：比如 “编程问题” source（来源）：可以是具体用户、具体对话ID 组合起来就是完整分机号：编程问题 + 来自用户张三 → 只转给张三专属的编程代理 4.服务（Services）—— 呼叫中心的后勤部门（你平时看不到但离了不行 服务名字 呼叫中心比喻 实际干啥 Worker 客服工位 真正跑代理代码的电脑进程 Gateway 总机姐姐 收发所有电话，决定打给哪个工位 Registry 花名册 记录“哪个代理能接什么分机” Routing 智能转接系统 根据分机号把电话精准送到对应代理 AgentState 员工档案柜 保存每个代理的记忆（上文、历史对话） 5.后端选项—— 呼叫中心可以开一家小店，也可以开全国连锁 后端类型 比喻 适合场景 内存（In-Memory） 你家客厅开个2人小呼叫中心 玩玩、调试、写脚本 Python 服务 市中心一间办公室 小团队用 Microsoft Orleans 全国连锁呼叫中心 + 云调度 上千人同时用、生产环境 gRPC 不同城市办公室之间的电话专线 分布式部署 完整工作流程（用你之前的多代理例子来说） 你问：“帮我用Python从零写一个神经网络”\n系统生成一张工单（事件） 工单扔到“编程问题”这个总机号（主题） 两个分析代理早就登记了“我能接编程问题” → 同时接到电话（并行！） 分析代理1（追求高效）开始写答案 分析代理2（追求简单）也开始写答案 两个答案写完后，再生成新工单扔给“优化总结”分机 优化代理接到后，把两份答案对比、补漏、排版成Markdown → 给你 整个过程没有“你去叫谁”，全靠“铃响了谁接”，这就是发布-订阅（观察者模式）的灵魂。\n2.2 关键概念 Agent (智能体)：具有特定角色（如“程序员”、“产品经理”）。 ID: 由 namespace (命名空间) 和 name 组成。 Topic (话题)：Agent 订阅话题来接收消息（类似消息队列）。 Lifecycle (生命周期)：Agent 并不是一直活着的。当有消息发给它时，系统会激活它；闲置时可能会休眠。 2.3 使用原理 AutoGen 的核心原理是**发布-订阅（Pub-Sub）**模型结合事件驱动架构：\n代理订阅感兴趣的事件主题。 当事件发布时，匹配订阅的代理处理它，可能触发新事件或调用工具（如 LLM、网页浏览）。 对于 RPC 等模式，在事件上层构建请求/响应。 代理生命周期：按需激活，无需显式创建/销毁。 数据流：事件携带上下文，代理可修改状态、调用外部 API 或发出新事件。 原理优势：解耦代理，易于扩展和调试。结合 LLM（如 OpenAI），代理可生成智能响应。\nAutoGen代理如何判断“我对这个事件感兴趣”？ 关键点：流程说明\n代理自己提前“登记”感兴趣的分机号（订阅主题）。 每来一个事件（电话），系统就看事件的分机号（TopicId）和自己登记的分机号对不对得上。 对得上 → 感兴趣 → 接电话！对不上 → 完全忽略。 匹配方式超级灵活：可以精确匹配，也可以“*通配符”批量匹配。 下面用最接地气的例子给你讲明白。\n用“客服呼叫中心”再讲一遍（你已经熟悉这个比喻了）\n代理提前去总机登记： 代码代理说：“我能接所有 type=编程问题 的电话！” 数学代理说：“我只接 type=数学计算:* 的电话（*表示不管是谁打的都接）” 用户专属代理说：“我只接 type=用户提问 AND source=用户张三 的电话” 用户打进来一个电话（事件） 事件内容： type = “编程问题” source = “用户张三” 系统（Routing服务）立刻拿这张工单去比对所有代理的登记表： 代码代理登记的是 “编程问题” → 完全匹配 → 响铃！ 数学代理登记的是 “数学计算” → 不匹配 → 不响铃 用户专属代理登记的是 “编程问题 + 用户张三” → 也匹配 → 也响铃！ 结果：代码代理和用户专属代理同时接到这个任务（可以并行干活） 这就是整个匹配过程！\n函数 大白话名字 作用 举例 Matcher “我感不感兴趣” 输入一个事件TopicId → 返回 True / False Matcher = lambda topic: topic.type.startswith(“编程”) Mapper “转给我哪个工位” 如果感兴趣了，把这个事件转给具体哪个代理实例 Mapper = lambda topic: AgentId(type=“代码代理”, key=topic.source) 代码长这样（真实Python写法）：\n# 代码代理订阅所有编程问题（用通配符 * 表示“我全都要”） subscription = Subscription( matcher=lambda topic: topic.type == \"编程问题\", # 精确匹配type # matcher=lambda topic: \"编程\" in topic.type # 模糊包含也行 # matcher=lambda topic: topic.type.startswith(\"com.ai.\") # 前缀匹配也行 mapper=lambda topic: AgentId(type=\"代码代理\", key=\"default\") # 都转给同一个默认实例 ) # 数学代理用通配符订阅所有数学相关 subscription2 = Subscription( matcher=lambda topic: topic.type.startswith(\"数学计算:\"), # :后面是source，随便 mapper=lambda topic: AgentId(type=\"数学代理\", key=topic.source.split(\":\")[1]) # 按来源动态创建不同实例 ) 支持的匹配方式汇总（超级灵活！）\n匹配方式 代码例子 大白话解释 完全相等 topic.type == “编程问题” 分机号一模一样才接 前缀匹配 topic.type.startswith(“com.microsoft.”) 所有微软内部事件都接 包含关键词 “数学” in topic.type 只要提到数学我就接 通配符 * topic.type == “用户提问:*” 所有用户提问我都接，不管是谁 正则表达式 re.match(r\"编程\\d+\", topic.type) 编程1、编程2、编程123 都接 组合条件 topic.type == “编程问题” and topic.source == “张三” 只有张三的编程问题我才接 实际运行时发生了什么（一步一步）\n代理启动时，把自己的 Matcher 和FD Mapper 函数注册到 Registry（花名册） 有人发布一个事件 → Routing 服务拿到事件 Routing 遍历所有订阅： 挨个调用每个代理的 matcher(event) 返回 True 的代理全被叫醒 再用 mapper(event) 决定具体转给哪个实例（可能动态创建新实例！） 事件被送到对应代理的“事件处理器”里执行 AutoGen订阅机制真实运行示例 import asyncio # 引入异步库，让程序可以“同时等多个电话”而不卡住 观察者模式思维：整个系统是异步事件驱动的，代理像“客服在座位上等铃响”，不用自己不停问“有没有活”。\nfrom autogen_core.base import MessageContext # 消息上下文，事件到来时会带上 from autogen_core.components import DefaultTopicPubSub, RoutedAgent, message_handler from autogen_core.application import SingleThreadedAgentRuntime # 单线程运行时（本地调试用） 观察者模式思维：\nRoutedAgent = 可订阅的观察者（Observer） DefaultTopicPubSub = 主题总线（Subject） message_handler = 观察者收到通知后执行的方法 # 1. 定义一个“代码代理”——观察者本人 class CodeWriterAgent(RoutedAgent): # 继承RoutedAgent，表示它能被路由（能订阅） def __init__(self, description: str): super().__init__(description) # 初始化父类，告诉系统“我是一个可订阅的代理” # 装饰器：当收到匹配的事件时，自动调用这个方法（这就是观察者被通知！） @message_handler async def handle_user_message(self, message: dict, ctx: MessageContext): print(f\"【代码代理收到任务】用户说：{message['content']}\") reply = f\"我来写代码啦！这里是解决方案：\\n```python\\n# 示例代码\\ndef hello():\\n print('Hello from AutoGen!')\\n```\" # 把结果发回给原来的主题（相当于回电话） await self.publish_message({\"content\": reply}, topic_id=ctx.topic_id) 观察者模式核心在这里：\n@message_handler = “我注册了一个观察方法” 当系统发现事件匹配时，自动调用这个方法 → 被观察者（Subject）主动通知观察者（Observer） 代理完全不知道谁发的消息，只管处理 → 完美解耦 async def main(): # 2. 创建运行时 = 创建“事件总线”（被观察者/Subject） runtime = SingleThreadedAgentRuntime() 观察者模式思维：runtime 就是整个系统的“大脑”，负责维护“谁订阅了什么”。\n# 3. 注册代理 + 订阅主题 —— 这就是观察者向被观察者注册！ await CodeWriterAgent.register( runtime, # 把代理注册到总线 type=\"code_writer\", # 代理类型名称 factory=lambda: CodeWriterAgent(\"我是一个专业的代码生成代理\"), # 如何创建实例 subscriptions=lambda topic: topic.type == \"programming_task\" # ← 关键！订阅规则 ) 逐行拆解 subscriptions=lambda topic: topic.type == “programming_task”\n这是一个Matcher 函数（判断“我感不感兴趣”） 每当有新事件到来，系统会遍历所有已注册的代理，调用这个 lambda 如果返回 True → “铃响了！这个代理要被唤醒” 这就是观察者模式中最经典的“注册兴趣”步骤！ # 4. 启动默认的发布-订阅总线 DefaultTopicPubSub.register(runtime) 观察者模式思维：激活总线，现在所有订阅都生效了。\nruntime.start() # 启动运行时，开始监听事件 print(\"系统已启动，代码代理正在等待编程任务...\") 观察者模式思维：代理现在坐在工位上，耳朵竖着等铃响\n# 5. 模拟用户发布一个事件 —— 相当于“有人打进电话” await runtime.publish_message( {\"content\": \"帮我写一个Python快速排序\"}, topic_id={\"type\": \"programming_task\", \"source\": \"user123\"} # 事件的分机号 ) 观察者模式关键时刻：\n事件发布 → 总线收到 总线遍历所有订阅 → 调用 lambda → 返回 True 自动把事件路由给 CodeWriterAgent @message_handler 方法被调用 → 打印“收到任务” → 回复代码 await asyncio.sleep(2) # 等待2秒看结果 await runtime.stop() # 停止系统 完整运行逻辑图（观察者模式视角）\n角色 代码对应部分 观察者模式术语 被观察者（Subject） runtime + DefaultTopicPubSub 事件总线 观察者（Observer） CodeWriterAgent 代码代理 注册观察 CodeWriterAgent.register(…, subscriptions=…) attach(observer) 发布事件 runtime.publish_message(…) notify() 收到通知 @message_handler 方法被调用 update() 总结一句话\n“代理订阅 = 观察者提前告诉系统‘这种电话我接’，事件发布 = 被观察者喊一声‘来电话啦！’，系统自动遍历所有观察者，问一遍‘你接吗？’，回答‘接’的就自动被叫醒干活 —— 整个过程代理之间互不认识，完全靠系统自动通知，这才是真正的观察者模式！”\n技术原理解释（Matcher 函数和 Mapper 函数） AutoGen文档里写了两个核心函数，就是“判断感兴趣”和“转给谁”的关键：\n2.4 实际使用场景 自动化任务：如代码审查（一个代理生成代码，另一个审查）。 研究与数据分析：多代理协作查询数学、化学问题，或浏览网页获取实时信息。 聊天机器人：构建多代理聊天系统，一个代理处理用户输入，另一个调用工具。 分布式 AI 系统：在云环境中部署代理团队处理大规模数据。 游戏/模拟：代理模拟角色互动。 企业应用：如客服系统，多代理分工处理查询。 案例：在 README 中，展示网页浏览代理查询 GitHub 贡献者，或多代理处理数学/化学查询。\n2.5 功能模块说明 模块名称 作用 适用场景 autogen-core 提供消息总线、事件处理、RPC。 高级开发，需要构建分布式、跨语言 Agent 系统。 autogen-agentchat 提供 AssistantAgent, UserProxy 等高级封装。 新手推荐。构建聊天机器人、任务编排。 autogen-ext 提供模型客户端（OpenAI/Azure）和工具（MCP）。 连接大模型 API，连接外部工具（浏览器、终端）。 AutoGen Studio 无代码/低代码的可视化界面。 演示、原型设计，不想写代码时使用。 你可以把 AutoGen 想象成你在组装一台 “超级电脑” 或者经营一家 “AI 公司”。为了让这个系统灵活好用，微软把代码拆成了四个不同的零件包。\n我用大白话 + “开公司”的例子给你逐一解释：\n没问题！作为一个刚接触的新手，看到这些带横杠的英文包名确实容易晕。\n你可以把 AutoGen 想象成你在组装一台 “超级电脑” 或者经营一家 “AI 公司”。为了让这个系统灵活好用，微软把代码拆成了四个不同的零件包。\n我用大白话 + “开公司”的例子给你逐一解释：\n1. autogen-core —— 公司的地基和电话线 别名：核心底层 大白话原理： 这是最底层的东西，你平时写代码可能很少直接用到它，但没它不行。它负责脏活累活，比如： 保证 Agent A 发的消息，Agent B 能收到。 如果 Agent 很多，它负责安排谁在哪个进程里运行。 它定义了大家沟通的“语言标准”（事件）。 比喻： 这就是公司的办公大楼、电话线路和会议室。它不干具体的业务，但提供了员工（Agent）工作的物理场所和沟通渠道。没有它，员工没法上班，也没法打电话。 2. autogen-agentchat —— 公司的员工和管理制度 【新手最常用】 别名：聊天代理层（应用层） 大白话原理： 这是你90%的时间都在打交道的部分。这里面封装好了各种现成的“员工模板”。 你想造一个会写代码的 AI？用这里的 AssistantAgent。 你想造一个代表用户的 AI？用这里的 UserProxy。 你想让两个 AI 聊天？用这里的代码把它们连起来。 比喻： 这就是公司的招聘启事和员工手册。 你通过它来定义：“你是程序员，叫小王”、“你是产品经理，叫小李”。你在这里指挥他们干活。 新手写代码，主要就是 import 这个包里的东西。 3. autogen-ext —— 员工的外部工具包 别名：扩展包/插件包 大白话原理： AutoGen 本身是个空架子，它得连上大模型（比如 GPT-4）或者外部工具才能干活。 你想用 OpenAI 的模型？你需要 autogen-ext[openai]。 你想用 Azure 的模型？你需要 autogen-ext[azure]。 你想让 AI 能控制浏览器？你需要这里的 MCP 工具扩展。 之所以把这些拆出来，是因为不想让你安装主程序时，被迫下载一堆你用不到的驱动。 比喻： 这就是员工的电脑、软件和外设。 你招了人（AgentChat），安排了工位（Core），但还没给他们配电脑。如果你想让他们用微软的 Word 干活，你就装个“微软扩展包”；如果你想让他们用谷歌的 Docs，你就装个“谷歌扩展包”。按需购买，随插随用。 4. AutoGen Studio —— 傻瓜式老板控制台 别名：可视化界面 大白话原理： 这是一个网页界面（UI）。给那些不想写代码，或者想快速给老板演示的人用的。 你不需要在黑乎乎的命令行里敲代码。 你在网页上点点鼠标，“拖拽”出一个 Agent，设置它的名字，就能在这个网页里跟它聊天。 比喻： 这就是极品飞车游戏的驾驶界面。 前面的三个（Core/AgentChat/Ext）相当于你在车库里手搓零件造赛车。而 AutoGen Studio 相当于直接给你一个做好的界面，你只需要握着方向盘（鼠标）开就行了，不用管引擎是怎么接线的。 总结：他们之间的关系 如果我们要完成一个任务：“让 AI 帮我写个贪吃蛇游戏”。\nautogen-core 在后台默默搭建了消息通道，确保信号畅通。 你写代码调用 autogen-agentchat，创建了一个“程序员 Agent”和一个“测试员 Agent”。 因为你要用 GPT-4 的智力，所以你安装了 autogen-ext 来连接 OpenAI 的 API。 如果你懒得写代码，你想直接用鼠标点一点就生成游戏，你就打开 AutoGen Studio。 给新手的建议 如果不写代码，只想玩玩：直接去研究 AutoGen Studio。 如果是开发人员，想写 Python 代码： 安装时：pip install autogen-agentchat autogen-ext[openai] 写代码时：主要关注 autogen-agentchat 里的写法。 不用太纠结 autogen-core，除非你要搞超级复杂的分布式系统。 安装(windows) 作为 Windows 用户，建议使用 PowerShell 或 VS Code 的终端。\n第一步：环境准备 确保你安装了 Python 3.10 或更高版本。 在 CMD 或 PowerShell 中输入 python –version 检查。\n第二步：创建虚拟环境 (强烈推荐) 不要把包安装到全局环境，容易冲突。\n# 1. mkdir (Make Directory) 创建新目录，cd (Change Directory) 切换当前工作目录 mkdir MyAutoGenProject cd MyAutoGenProject # 2. 创建虚拟环境 (venv)，让Python 在这个文件夹里建一个“独立小房间”。以后安装的软件只放在这个小房间里，不会弄脏你电脑的其他地方 python -m venv .venv # 3. 激活虚拟环境 (Windows PowerShell) # 如果提示权限错误，先运行：Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser .\\.venv\\Scripts\\Activate #如果系统提示“禁止运行脚本”或红色报错，请执行下面这行命令解锁权限，然后再执行上面的激活命令： Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser # 激活成功后，命令行前面会出现 (.venv) 字样 第三步：安装 AutoGen v0.4 核心包 根据参考文件 README (1).md，v0.4 采用了分包策略，不再是以前的一个 pyautogen 包了\n执行安装命令：\npip install -U \"autogen-agentchat\" \"autogen-ext[openai]\" 请仔细看这个命令，我来逐词解释：：\n“autogen-agentchat” 【技术原理】：安装 AutoGen 的高层应用 API（对应文档中的 AgentChat 层）。 【大白话】：这是主程序。也就是你要用来创建“助理Agent”、“用户Agent”的核心代码包。注意，v0.4 必须装这个，而不是旧版的 pyautogen。 “autogen-ext[openai]” 【技术原理】：安装 AutoGen 的扩展包，并指定 openai 作为附加依赖（Extra Dependencies）。 【大白话】：这是配件包。AutoGen 本身是个空壳，它需要连大模型。这个包里包含了连接 OpenAI（或者兼容 OpenAI 接口的模型，如通义千问、DeepSeek）所需的驱动程序。 第四步：配置 API Key 并验证 设置临时环境变量\n为了验证安装成功，我们需要设置 API Key。在 PowerShell 中输入\n$env:OPENAI_API_KEY=\"sk-你的密钥放这里\" 【技术原理】：在当前 PowerShell 会话中设置名为 OPENAI_API_KEY 的环境变量。 【大白话】：告诉电脑：“待会儿如果有程序要查户口（找密钥），就把这串密码给它。”（注意：关掉窗口后这个设置会失效，下次要重新输）。 创建测试脚本验证\nimport asyncio # 尝试导入 v0.4 的新包，如果不报错说明安装成功 from autogen_agentchat.agents import AssistantAgent from autogen_ext.models.openai import OpenAIChatCompletionClient async def main(): print(\"✅ AutoGen v0.4 环境安装成功！\") # 简单的创建一个客户端实例测试 client = OpenAIChatCompletionClient(model=\"gpt-4o\") print(f\"✅ 客户端创建成功: {client}\") if __name__ == \"__main__\": asyncio.run(main()) 第五步：运行测试 python test_install.py 【反馈】：如果屏幕打印出 ✅ AutoGen v0.4 环境安装成功！，恭喜你，你的 Windows 环境已经完美就绪！ 总结：老手和新手的区别 旧版 (v0.2)：以前大家习惯 pip install pyautogen。 新版 (v0.4)：现在是 模块化安装。 如果你只做普通对话，装 autogen-agentchat。 如果你要连 OpenAI，加装 autogen-ext[openai]。 如果你要用 Azure，加装 autogen-ext[azure]。 实战：新人如何开始使用 (代码案例) 我们从最基础的开始，逐步深入。请在项目目录下创建 .py 文件运行。\n场景一：Hello World (单兵作战) 目标：创建一个助手，让它说“Hello World”。 核心类：AssistantAgent (助理代理), OpenAIChatCompletionClient (模型客户端)。\n创建文件 hello.py:\nimport asyncio from autogen_agentchat.agents import AssistantAgent from autogen_ext.models.openai import OpenAIChatCompletionClient async def main() -\u003e None: # 1. 定义模型客户端 (这里用 gpt-4o 或 gpt-3.5-turbo) model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") # 2. 创建一个助手 Agent agent = AssistantAgent(\"my_assistant\", model_client=model_client) # 3. 运行任务并打印结果 print(await agent.run(task=\"请用中文向我问好，并写一句关于AI的诗。\")) # 4. 关闭客户端 await model_client.close() if __name__ == \"__main__\": asyncio.run(main()) 场景二：多智能体协作 (团队作战) 标：一个数学专家和一个化学专家，由一个主助手协调回答问题。 原理：使用 AgentTool 将一个 Agent 包装成另一个 Agent 的“工具”。这是 v0.4 推荐的简单编排方式。\n创建文件 team.py:\n# --- 导入部分 --- # asyncio 是 Python 用来处理并发任务的标准库。 # 简单理解：它可以让程序在等待（比如等待AI回复）的时候不卡死，去处理别的事情。 import asyncio # 从 autogen_agentchat 库中导入 AssistantAgent。 # 这是一个通用的 AI 助手类，可以把它看作一个具体的“人”或“角色”。 from autogen_agentchat.agents import AssistantAgent # 导入 AgentTool。 # 它的作用是把一个 Agent 包装成一个“工具”，这样其他的 Agent 就可以像调用函数一样调用它。 from autogen_agentchat.tools import AgentTool # 导入 Console。这是一个辅助工具，用来在黑框框（终端）里漂亮地打印出 AI 的对话过程。 from autogen_agentchat.ui import Console # 导入 OpenAI 的客户端。这是程序的大脑，负责连接 GPT-4 等模型。 from autogen_ext.models.openai import OpenAIChatCompletionClient # --- 主函数定义 --- # async def 定义了一个异步函数。 # 在 Python 中，如果函数内部涉及网络请求（比如问 GPT），通常都要用 async 定义。 async def main() -\u003e None: # 1. 初始化模型客户端 # 这里我们配置了使用 \"gpt-4o\" 模型。 # 注意：实际运行通过 api_key 连接，通常从环境变量中自动读取 OPENAI_API_KEY。 model_client = OpenAIChatCompletionClient(model=\"gpt-4o\") # --- 2. 创建专员 (子 Agent) --- # 创建第一个 Agent：数学专家 # name: 给这个 Agent 起个名字，方便日志区分。 # system_message: \"人设\"指令，告诉 AI 它该扮演什么角色，只做什么事。 math_agent = AssistantAgent( name=\"math_expert\", model_client=model_client, system_message=\"你是一个数学专家，只回答数学计算问题。\", ) # 【关键步骤】将 Agent 包装成工具 # 正常的 Agent 是用来对话的，但在这里，我们要把它变成主管手中的一个“计算器”。 # return_value_as_last_message=True: 意思是这个工具运行完，直接把最后一句回复作为结果返回给调用者。 math_tool = AgentTool(math_agent, return_value_as_last_message=True) # 创建第二个 Agent：化学专家 # 逻辑同上，只是人设不同。 chem_agent = AssistantAgent( name=\"chemistry_expert\", model_client=model_client, system_message=\"你是一个化学专家，只回答分子式和化学反应问题。\", ) # 同样将其包装成工具 chem_tool = AgentTool(chem_agent, return_value_as_last_message=True) # --- 3. 创建主控 Agent (Manager) --- # 这个 Agent 是用户直接对话的对象，类似于“包工头”或“前台”。 manager = AssistantAgent( name=\"manager\", # 它的指令非常重要：告诉它在什么情况下使用什么工具。 system_message=\"你是一个总管。遇到数学问题调用 math_expert，遇到化学问题调用 chemistry_expert。\", model_client=model_client, # tools: 这里把上面做好的两个“工具人”塞给它。 # 当 GPT 判定用户问题需要数学知识时，它就会自动调用 math_tool。 tools=[math_tool, chem_tool], ) # --- 4. 运行任务 --- # task: 这是用户发出的真实指令。包含了一个化学问题和一个数学问题。 # manager.run_stream(...): 让 manager 开始思考并处理任务，以“流式”方式返回（像打字机一样一个字一个字蹦）。 # Console(...): 这是一个 UI 包装器，它会自动接收流式数据并漂亮地打印在屏幕上。 # await: 这是一个等待指令，意思是“程序在这里暂停，直到对话完全结束再往下走”。 await Console(manager.run_stream(task=\"请告诉我水的分子量是多少？然后算一下 2的10次方是多少？\")) # --- 程序入口 --- # 这是 Python 的标准写法。 # 如果直接运行这个文件（而不是被别的代码 import），就执行下面的代码。 if __name__ == \"__main__\": # asyncio.run() 是启动异步程序的“钥匙”。 # 它负责创建一个事件循环，并运行 main() 函数。 asyncio.run(main()) 常用命令与参数速查 核心类参数说明 AssistantAgent (最常用的类) agent = AssistantAgent( name=\"agent_name\", # [必填] Agent 的名字，用于标识 model_client=client, # [必填] 模型客户端实例 system_message=\"You are...\", # [可选] 系统提示词（人设） tools=[tool1, tool2], # [可选] 该 Agent 可用的工具列表 description=\"描述...\", # [可选] 描述该 Agent 能干什么（给其他 Agent 看的） max_tool_iterations=10, # [可选] 防止工具死循环调用的最大次数 model_client_stream=True # [可选] 是否开启流式输出 ) OpenAIChatCompletionClient client = OpenAIChatCompletionClient( model=\"gpt-4o\", # 模型名称 api_key=\"...\", # 如果不设环境变量，可在此传入 temperature=0.7, # 创意程度 (0-1) ) 运行与调试命令 运行代码： python your_script.py 启动 AutoGen Studio (UI)： autogenstudio ui --port 8080 --appdir ./my-app 然后在浏览器访问 http://localhost:8080。\nRoundRobinTeam 你是一个由三个智能体组成的协作系统，专门用于回答 AI 编程相关的问题：\n分析者 A 和 分析者 B：各自独立理解用户提出的问题，并分别提供一个清晰、可行、技术准确的回答。 评审优化者 C：对比 A 与 B 的回答，选出质量更高的一方作为主答案；同时参考次优回答中的有效信息，对主答案进行查漏补缺、逻辑完善和语言优化；最终输出一个经过融合与提升的最终回答，并简要说明优化理由。 请严格按照上述角色分工协作，确保最终回答准确、完整、实用，且优于任一初始回答。\n【2025年11月版】完全小白也能一键部署到互联网的三专家协作系统（支持阿里通义千问 + DeepSeek）\n目标：\n4～5个人同时访问（并发极低） 完全免费/超低成本部署（推荐 Railway / Fly.io / Render） 使用国产模型：写代码用 DeepSeek-Coder，专家思考用通义千问（Qwen-Max / Qwen-Plus） 代码带超级详细中文逐行注释 + 大白话解释 Autogen源码：\n# ================================== app.py 开始 ================================== import os # 用于读取系统环境变量（就是你设置的API密钥） import asyncio # AutoGen 0.4+ 全部都是异步的，必须导入 from fastapi import FastAPI, Request # FastAPI = 把AI变成网页的超级简单框架 from fastapi.responses import HTMLResponse # 返回HTML网页用的 from fastapi.templating import Jinja2Templates # 用来渲染网页模板 from pydantic import BaseModel # 用来定义用户发来的数据格式（就是问题） # ------------------- AutoGen 最新核心库（2025年11月版） ------------------- from autogen_agentchat.agents import AssistantAgent # 智能体类 from autogen_agentchat.teams import RoundRobinTeam # 团队类（轮流发言） from autogen_agentchat.conditions import MaxMessageTermination # 结束条件（最多说几句话） # ------------------- 国产模型支持（阿里通义千问 + DeepSeek） ------------------- from autogen_ext.models.dashscope import DashScopeChatCompletionClient # 通义千问 from autogen_ext.models.deepseek import DeepSeekChatCompletionClient # DeepSeek # ------------------- 创建网页应用 ------------------- app = FastAPI(title=\"我的AI三专家编程助手\") # 整个网站的“大脑” templates = Jinja2Templates(directory=\"templates\") # 网页模板放在 templates 文件夹里 # ------------------- 定义用户发来的数据格式 ------------------- class QuestionRequest(BaseModel): # 用户发来的JSON长这样：{\"question\": \"你的问题\"} question: str # 只有一个字段，就是问题本身 # ------------------- 全局变量：只创建一次团队，省钱又快 ------------------- _expert_team = None # 一开始是空的，第一次有人问问题时才创建 # ------------------- 核心函数：创建三专家团队 ------------------- async def create_expert_team(): # 大白话：这里给每个专家装上不同的大脑 print(\"正在创建三专家团队（只创建一次）...\") # 从环境变量读取密钥（部署平台会自动帮你填） dashscope_key = os.getenv(\"DASHSCOPE_API_KEY\") # 阿里通义千问的key deepseek_key = os.getenv(\"DEEPSEEK_API_KEY\") # DeepSeek的key if not dashscope_key: raise ValueError(\"错误：没有设置 DASHSCOPE_API_KEY\") if not deepseek_key: raise ValueError(\"错误：没有设置 DEEPSEEK_API_KEY\") # 专家1：代码专家 → 用DeepSeek（全球最强代码模型） coder = AssistantAgent( name=\"代码大师（DeepSeek）\", model_client=DeepSeekChatCompletionClient( model=\"deepseek-coder\", # 也可以改成 deepseek-coder-33b（更强） api_key=deepseek_key ), system_message=\"你只负责写出完美可运行的代码 + 超级详细的中文注释。用简体中文回答。\" ) # 专家2：原理专家 → 用通义千问（理解力最强） analyst = AssistantAgent( name=\"原理大神（通义千问）\", model_client=DashScopeChatCompletionClient( model=\"qwen-plus\", # qwen-max 更强，但稍贵一点 api_key=dashscope_key ), system_message=\"你负责用最容易懂的大白话讲解技术原理、设计思路、为什么这样写更好。\" ) # 专家3：最终评审优化专家 → 也用通义千问 reviewer = AssistantAgent( name=\"总编辑（通义千问）\", model_client=DashScopeChatCompletionClient( model=\"qwen-plus\", api_key=dashscope_key ), system_message=\"\"\" 你是最终把关人，必须做到以下5点： 1. 对比前面两个专家的回答 2. 选出更好的作为主答案，并说明至少3个理由 3. 把另一个专家的亮点全部融合进来 4. 补充两人漏掉的关键点（尤其是新手最容易踩的坑） 5. 输出最终完美答案：完整代码 + 逐行注释 + 大白话解释 + 运行逻辑分析 用简体中文，语气超级友好！ \"\"\" ) # 把三个人拉进一个“轮流发言”的团队（A→B→C→A→B→C...） team = RoundRobinTeam( name=\"AI编程三剑客\", agents=[coder, analyst, reviewer], # 发言顺序：代码→原理→评审 max_rounds=9, # 最多9条消息（3轮完整讨论） termination_condition=MaxMessageTermination(9) # 防止无限聊天 ) return team # 【大白话解释】：把刚才创建好的“三专家团队”这个对象“交出去”给调用者 # 【原理】：create_expert_team() 函数的最后一步就是 return team， # 这样外面调用 await create_expert_team() 就能拿到完整的团队对象 # 以后所有提问都会用这个团队来讨论 # ------------------- 获取团队（带缓存） ------------------- async def get_team(): # 定义一个异步函数，专门负责“拿到团队” # 为什么叫“带缓存”？因为我们只想创建一次团队，后面重复用，省钱又快！ global _expert_team # global 关键字：告诉 Python “我要使用文件最上面定义的那个全局变量 _expert_team” # _expert_team 最开始是 None（空） if _expert_team is None: # 第一次有人来问问题时，这里是 None，所以会走进这个 if # 【大白话】：第一次访问网站的人触发了团队的“出生仪式” _expert_team = await create_expert_team() # await：因为 create_expert_team() 是异步函数，必须等它创建完团队才能继续 # 创建完后就把团队保存到全局变量 _expert_team 里，下次就不会再创建了 # 【原理】：这就是“懒加载 + 单例模式”，只创建一次，后面直接复用 return _expert_team # 无论第一次还是第100次，都把同一个团队对象返回给调用者 # 这样所有用户共享同一个三专家团队，成本最低、速度最快！ # ------------------- 网页首页 ------------------- @app.get(\"/\", response_class=HTMLResponse) # @app.get(\"/\") 是 FastAPI 的装饰器，意思是： # 当有人在浏览器输入你的网站域名（比如 https://xxx.up.railway.app/）时，就执行下面的函数 # response_class=HTMLResponse：告诉 FastAPI 要返回一个完整的网页，而不是纯文字或JSON async def home(request: Request): # 这个函数负责显示网站的首页 # request: Request 是 FastAPI 自动传进来的，代表这次访问的所有信息（我们这里暂时用不到） # 把 templates/index.html 这个网页显示出来 return templates.get_template(\"index.html\").render({\"request\": request}) # 【大白话解释】： # 1. templates.get_template(\"index.html\") → 去 templates 文件夹里找到 index.html 这个网页文件 # 2. .render({\"request\": request}) → 把一些数据塞进网页（这里只塞了一个 request，Jinja2模板需要） # 3. 最后返回这个渲染好的完整网页给浏览器，用户就看到漂亮的输入框了！ # ------------------- 核心API：接收问题，返回答案 ------------------- @app.post(\"/ask\") # @app.post(\"/ask\") 表示：当前端用 POST 方法发请求到 /ask 这个地址时，执行下面的函数 # 前端的 JavaScript 代码里 fetch('/ask', ...) 就是调用这里！ async def ask_question(req: QuestionRequest): # req 就是用户发来的数据，格式是 {\"question\": \"用户的问题\"} # QuestionRequest 是我们前面用 pydantic 定义的模型，会自动检查数据格式 question = req.question.strip() # .strip() 把用户输入前后的空格、换行都去掉，防止空问题 if not question: # 如果用户只点了按钮但啥也没写，就返回一个友好的错误 return {\"error\": \"问题不能为空哦~\"} try: # 开始真正干活！下面所有代码都包在 try 里，出错就不会崩溃 team = await get_team() # 先拿到我们已经准备好的三专家团队（如果还没创建，就会自动创建） print(f\"收到问题：{question}\") # 在服务器后台打印一下，便于你看日志，知道有人来问问题了 # 真正开始三专家讨论！这是整个程序的核心！ result = await team.run(task=question) # team.run() 是 AutoGen 0.4+ 的官方方法 # 它会让三个专家轮流发言9轮，最终得出一个完美答案 # await 必须加，因为这是异步操作，要等他们讨论完 # 返回最终完美答案给前端网页 return { \"question\": question, # 把问题原样返回，方便前端显示 \"answer\": result.final_output, # 这就是三专家最终商量出来的超级详细答案！ \"status\": \"success\" # 告诉前端“成功了” } except Exception as e: # 如果中间任何地方出错了（比如网络问题、API余额不足），都会走到这里 print(f\"出错了：{e}\") # 在后台打印真实错误，方便你调试 return {\"error\": f\"系统出错：{str(e)}\"} # 给用户一个友好的提示，同时把真实错误也显示（上线后可以隐藏） 2、网页文件（超级简单）\n新建文件夹 templates，里面新建 index.html，复制下面全部内容：\n\u003c!DOCTYPE html\u003e AI三专家编程助手 🚀 AI三专家编程助手 问任何编程问题，三位大佬会给你最完美的答案！（代码+详细解释） 立即提问 答案会在这里显示～ 3.详细的 GitHub + Railway 一键部署教程（手把手截图级）\n步骤1：创建 GitHub 仓库（1分钟）\n打开 https://github.com/new Repository name 填：ai-expert-assistant（随便填） 点 Create repository 步骤2：把代码上传到 GitHub（3分钟）\n把上面两个文件保存到电脑一个文件夹里： ai-expert-assistant/ ├── app.py └── templates/ └── index.html 2.打开终端（Mac）或命令提示符（Windows），进入这个文件夹，运行：\ngit init git add . git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/你的用户名/ai-expert-assistant.git git push -u origin main （第一次会让你登录GitHub）\n步骤3：申请两个免费API密钥（5分钟）\n阿里通义千问：https://help.aliyun.com/zh/dashscope/developer-reference/tongyi-qwen-quick-start → 控制台 → API-KEY → 复制 DeepSeek：https://platform.deepseek.com/api-keys → 注册 → 直接复制 key 步骤4：Railway 一键部署（最简单！3分钟）\n打开 https://railway.app → 用 GitHub 登录 点右上角 “New Project” 选 “Deploy from GitHub” 选你刚创建的仓库 ai-expert-assistant Railway 自动检测到是 Python 项目，会让你确认 → 直接点 Deploy 部署完成后，点你的项目 → Variables 标签 → 加三行 DASHSCOPE_API_KEY 填你的通义千问key DEEPSEEK_API_KEY 填你的DeepSeek key PORT 8000 ​ 7.保存 → 等待30秒重新部署 → 点右上角的网址（类似 https://ai-expert-assistant.up.railway.app）\n大功告成！把这个网址发给你的4-5个朋友，他们就能无限使用了！\n本地先测试一下（可选）：\npip install fastapi uvicorn \"autogen-agentchat\" \"autogen-ext[dashscope,deepseek]\" uvicorn app:app --reload 现在你拥有了一个比 ChatGPT 还强的、完全属于自己的国产AI编程助手网站！🎉\nAutoGen组件代码解释指南 GraphFlow：这是一个用于结构化多代理工作流的工具，似乎可以可靠地控制代理执行顺序，但需注意实验性，可能有API变更。 Magentic-One：一个通用多代理系统，证据显示它擅长复杂任务协作，但随机性可能导致不一致结果。 Swarm：OpenAI的轻量框架，用于代理协调，看起来易用但实验性质强，适合原型测试。 McpWorkbench：AutoGen的工具集成平台，帮助代理访问外部服务，安全风险需警惕。 这些组件的代码示例基于最新文档，通常涉及Python异步编程和代理实例化。逐行解释包括语法（技术细节）和大白话（简单原理）。每个组件的代码放在单独“文件”中展示。\nAutoGen框架是一个开源的多代理AI开发工具，由微软xAI团队维护，用于构建协作AI系统。下面这份调研笔记详细解释了您查询的代码示例与逐行解析，重点针对GraphFlow、Magentic-One、Swarm和McpWorkbench。笔记基于2025年最新文档和教程，整合了语法角度（技术细节，如变量赋值、函数调用）和大白话原理（简单比喻，如“像团队分工”）两种方式解释。每个组件的代码放在一个虚拟“文件”中（以代码块模拟），方便复制展示。笔记还包括组件定义、解决问题、运行原理、痛点、益处和案例。\n1. GraphFlow (图流/事件驱动工作流) 注意：在 AutoGen v0.4 中，没有一个类直接叫 GraphFlow，这个词通常指代基于图（Graph）的事件驱动工作流。这是 v0.4 的核心架构理念。\nGraphFlow 是 AutoGen 0.4+（尤其是 AgentChat API）中一个实验性的 multi-agent workflow 工具（目前还在快速迭代，API 可能会变）。它把多个 agent 当成图（graph）的节点，用有向边（edges）来精确控制它们之间的执行顺序和消息流动。\n解决了什么问题？ 以前 AutoGen 的 GroupChat（比如 RoundRobin、Selector）是“自由聊天”模式，agent 轮流发言，流程不固定，容易出现：\n对话乱序、重复 无法保证某些步骤一定先执行（比如必须先研究 → 再写代码 → 再审查） 难以做条件分支、循环、并行（fan-out/fan-in） GraphFlow 把 workflow 变成可编程的图，开发者可以明确说“这个 agent 完成后，下一步走哪个（或哪几个）”，让多 agent 协作变得确定性、可视化、可调试。\n运行原理\n用 DiGraphBuilder 构建一个有向图（Directed Graph） 每个节点 = 一个 agent 每条边 = “从 A 到 B 的消息流动”，可以加条件（condition=lambda msg: …） 执行时从入口节点（entry point / source nodes）开始，按图拓扑顺序自动推进，支持循环、条件分支、并发（多个 outgoing edges 时可以同时执行） 痛点解决 \u0026 带来的启示\n痛点：聊天式多 agent 太“随机”，企业级任务需要严格流程控制 启示：把多 agent 当成“工作流引擎”而不是“群聊”，更适合生产环境（如审批流、研究→写作→审查） 怎么用？一个简单案例（fan-out → fan-in） 任务：让一个 agent 生成一段文字，然后同时翻译成中文和日文，最后汇总。\n# 先导入异步运行必须的 asyncio import asyncio # 从 AutoGen 导入我们需要的几个核心类 from autogen_agentchat.agents import AssistantAgent # 基础的助手 Agent from autogen_agentchat.teams import DiGraphBuilder, GraphFlow # 图构建器和图流程 from autogen_agentchat.ui import Console # 用来在终端实时打印对话 from autogen_ext.models.openai import OpenAIChatCompletionClient # OpenAI 模型客户端 # 定义一个 async 主函数（AutoGen 0.4 全部用异步） async def main() -\u003e None: # 第1步：创建一个连接 OpenAI 的客户端（这里用 gpt-4o） # 你需要提前在环境变量里设置 export OPENAI_API_KEY=sk-... client = OpenAIChatCompletionClient(model=\"gpt-4o\") # 等价于以前的 OpenAIWrapper，只不过现在叫这个名字 # 第2步：创建 4 个不同的助手 Agent（每个都用同一个模型） generator = AssistantAgent( name=\"generator\", # Agent 的名字，后面图里会用到 model_client=client, # 用上面创建的 OpenAI 客户端 system_message=\"你是一个内容生成专家，请根据用户任务生成一段英文段落。\" # 系统提示词，决定 Agent 的角色 ) translator_zh = AssistantAgent( name=\"translator_zh\", model_client=client, system_message=\"你只负责把英文翻译成简体中文，不要加额外解释。\" ) translator_ja = AssistantAgent( name=\"translator_ja\", model_client=client, system_message=\"你只负责把英文翻译成日文，不要加额外解释。\" ) summarizer = AssistantAgent( name=\"summarizer\", model_client=client, system_message=\"把所有翻译结果汇总，用中文输出最终版本。\" ) # 第3步：开始构建一张“流程图” builder = DiGraphBuilder() # 创建一个空的图构建器 # 把上面 4 个 Agent 都加入图里（变成图的节点） builder.add_node(generator) builder.add_node(translator_zh) builder.add_node(translator_ja) builder.add_node(summarizer) # 第4步：画箭头——决定执行顺序（边） builder.add_edge(generator, translator_zh) # generator 完成后 → 发消息给中文翻译 builder.add_edge(generator, translator_ja) # generator 完成后 → 同时发消息给日文翻译（并行！） builder.add_edge(translator_zh, summarizer) # 中文翻译完成后 → 发给汇总 Agent builder.add_edge(translator_ja, summarizer) # 日文翻译完成后 → 发给汇总 Agent # 第5步：把图和所有 Agent 打包成一个可以运行的“团队” flow = GraphFlow( participants=builder.get_participants(), # 所有参与的 Agent graph=builder.build() # 刚才画好的图 ) # 第6步：真正开始运行！任务从入度为 0 的节点（这里是 generator）开始 await Console(flow.run_stream( task=\"写一段介绍北京故宫的英文段落（大约100字）\" )) # 启动程序 asyncio.run(main()) 2. Magentic-One (磁性一号 / 全能团队) 是什么： 它不是一个功能，而是微软官方基于 AutoGen 打造的一个通用的、高性能的多智能体系统（System）。 大白话：它是一个现成的“复仇者联盟”。你不需要自己去写“程序员Agent”、“搜索Agent”，微软已经帮你写好了一组最强的 Agent 搭配，里面有一个类似“神盾局局长”的 Orchestrator 在指挥。 解决了什么问题： 通用性：以前你写 Agent 只能干一件事。Magentic-One 号称可以解决各种复杂任务（上网查资料 + 写代码 + 操作文件）。 自我修正：如果代码跑不通，它内部会自动循环修复，直到成功。 痛点与原理\u0026 启示： 痛点：新手自己组装的 Agent 团队往往很笨，容易陷入死循环。 原理：采用 Orchestrator（指挥官）+ Specialists（专家组：WebSurfer, Coder, Executor）的架构。 启示：把不同技能拆成独立 agent + 一个聪明指挥官，是解决“通用复杂任务”的有效模式 4 个专业 agent： WebSurfer：多模态网页浏览（看图、点击、填写表单） FileSurfer：本地文件系统读写 Coder：写代码 Executor（Computer Terminal）：执行代码、安装库 源码示例与逐行解析： (注意：Magentic-One 通常作为独立包 autogen-magentic-one 存在，以下演示其核心使用逻辑) import asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient # 假设安装了 magentic-one 扩展包 from autogen_magentic_one.agents import MagenticOneOrchestrator, MagenticOneCoder async def main(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # [1. 这里的核心是 Orchestrator (总指挥)] # Magentic-One 的厉害之处在于这个预设好的指挥官，它内置了非常复杂的策略 # 它知道什么时候该叫程序员，什么时候该叫浏览器 team_leader = MagenticOneOrchestrator( name=\"MagenticManager\", model_client=client ) # [2. 这是一个全能的运行入口] # 你不需要手动把 Agent 连起来，Magentic-One 封装好了 # 这行代码背后，可能有4-5个 Agent 在疯狂交互：上网查股价 -\u003e 写绘图代码 -\u003e 运行 -\u003e 存图 await team_leader.run_task( \"请上网查询微软过去一年的股价，并用 Python 画一张折线图保存为 stock.png\" ) if __name__ == \"__main__\": asyncio.run(main()) Magentic-One（开箱即用最强多智能体团队）—— 最详细注释版\nimport asyncio from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.teams.magentic_one import MagenticOne # 直接导入现成的团队 from autogen_agentchat.ui import Console async def main(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # 可以换其他模型 m1 = MagenticOne(client=client) # 一行创建一个完整 5-agent 团队 await Console(m1.run_stream(task=\"帮我查找最近 3 篇关于量子计算的 arXiv 论文，并用中文总结每篇的核心贡献\")) asyncio.run(main()) 逐行解释：\nMagenticOne(client=client)：内部自动创建 Orchestrator + 4 个专业 agent，已经配好工具（Playwright 浏览、Docker 代码执行等） m1.run_stream(task=…)：直接扔一个复杂任务，它会自动规划、浏览网页、下载 PDF、总结…… 这就是“开箱即用”的通用 agent 系统，几乎不需要你写任何 agent 定义。\n3. Swarm (蜂群模式 / 动态交接) 是什么： 这是 OpenAI 提出的一种轻量级多 Agent 模式，AutoGen v0.4 完美支持。它的核心概念是 Handoffs（交接）。 大白话：就像打电话给客服。\n你：“我要退款。” 客服A：“这事我管不了，但我知道‘退款专员B’能管，**转接（Handoff）**给B。” Agent 自己决定下一棒交给谁，而不是由一个总管来分配。 运行原理\n每个 agent 有 handoffs=[“agent_name”, …] 列表，告诉它可以把任务交给谁 agent 用特殊工具 handoff_to_xxx 把控制权完全交给下一个 agent（上下文共享） 整个团队像“接力赛”而不是“群聊 解决了什么问题：\n去中心化：不需要一个超级聪明的“大总管”来分配任务，Agent 自己就能根据对话上下文把锅甩给对的人。 灵活性：流程非常自然，像人类聊天一样流转。 痛点与原理\u0026 启示：\n痛点：传统的 GroupChat 有时候很乱，所有人都在一个群里抢着说话。 原理：每个 Agent 的工具箱里都有一个“转接工具”，返回 Handoff 对象。 启示：把多 agent 当成“服务路由”，非常适合对话式应用（客服、订票） 源码示例与逐行解析：\nimport asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.messages import Handoff from autogen_agentchat.teams import Swarm from autogen_ext.models.openai import OpenAIChatCompletionClient async def main(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # [1. 定义“接待员” Agent] # 注意 handoffs 参数：允许它把任务转交给 flight_agent receptionist = AssistantAgent( \"receptionist\", model_client=client, system_message=\"你是前台。如果用户问航班，转交给 flight_agent。\", handoffs=[\"flight_agent\"] # 核心：给它一个通讯录，告诉它能转给谁 ) # [2. 定义“航班专员” Agent] # 它的 handoffs 指向 receptionist，意味着处理完可以转回去，或者结束 flight_agent = AssistantAgent( \"flight_agent\", model_client=client, system_message=\"你是航班专员，负责查询机票。\", handoffs=[\"receptionist\"] ) # [3. 组建 Swarm (蜂群) 团队] # Swarm 模式不需要路由器，Agent 自己决定下一个是谁 team = Swarm([receptionist, flight_agent], model_client=client) # [4. 运行] # 用户问：查机票 -\u003e 前台(接单) -\u003e 前台(无能力) -\u003e 触发Handoff -\u003e 航班专员(接单) -\u003e 回答 await team.run(task=\"我想查一张去北京的机票\") if __name__ == \"__main__\": asyncio.run(main()) 这四个概念是 AutoGen v0.4 生态中非常核心、但也容易混淆的术语。它们分别代表了：工作流架构、超级智能体团队、交互模式、工具标准。\n为了让你直观理解，我将采用**“概念解析 + 源码与逐行注释合并”**的方式来展示。\nSwarm（接力式多智能体，类似客服路由）—— 最详细注释版\nimport asyncio from autogen_agentchat.agents import AssistantAgent # 基础 Agent from autogen_agentchat.teams import Swarm # Swarm 团队类 from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient async def main(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # 第1个 Agent：只负责查航班，查完必须把对话交给下一个 search_agent = AssistantAgent( name=\"flight_search\", model_client=client, system_message=\"你只负责查询航班信息，绝对不要自己订票。查完后必须使用 handoff 把对话交给 booking_agent。\", # 关键：handoffs 列表里写明它可以把任务交给谁 handoffs=[\"booking_agent\", \"user\"] # 可以交给订票员或直接交给用户 ) # 第2个 Agent：只负责订票和改签 booking_agent = AssistantAgent( name=\"booking\", model_client=client, system_message=\"你只负责订票、改签、退票等操作。完成后必须 handoff 给 user。\", handoffs=[\"user\"] # 只能交给用户，不能再交给别人 ) # 创建 Swarm 团队，第一个 Agent 会自动成为入口 team = Swarm(participants=[search_agent, booking_agent]) # 开始对话——用户说想查航班 await Console(team.run_stream( task=\"帮我查一下明天从北京到上海的航班，有什么便宜的？\" )) # 你会看到： # 1. search_agent 先回答航班信息 # 2. 自动 handoff（交接）给 booking_agent # 3. booking_agent 问你要不要订票 # 4. 最后交还给用户 asyncio.run(main()) 运行后你会看到：search_agent 查完航班 → 自动 handoff 到 booking_agent → booking_agent 问你要不要订 → 最后 handoff 回 user。\n4. McpWorkbench (MCP 工作台 / 通用工具接口) 是什么： McpWorkbench 是 AutoGen 提供的 Model Context Protocol (MCP) 客户端工具。MCP 是 Anthropic 发起的一个开放协议，让 LLM 能安全地调用外部工具服务器（比如 Playwright 浏览网页、文件系统、Git 等）。 大白话：以前你想让 AI 连 GitHub、连 Google Drive、连本地文件，你得给每个平台写一套 Python 代码。现在有了 MCP，就像 USB 接口。GitHub 提供了一个“USB设备”（MCP Server），AutoGen 提供了一个“USB插座”（McpWorkbench），插上就能用，不用写驱动代码。\n解决了什么问题：\n工具荒：开发者不用自己苦哈哈地写工具函数了，直接用社区现成的 MCP Server。 安全性：MCP Server 运行在独立进程里，不会搞坏你的主程序。 运行原理\n启动一个 MCP server（比如 @playwright/mcp 浏览网页） 用 McpWorkbench 连接这个 server 把 workbench 传给 AssistantAgent，agent 就能像调用普通工具一样调用 MCP 工具 痛点与原理\u0026 启示：\n痛点：连接外部世界（World Grounding）太难了，每个 API 文档都不一样。 原理：通过标准化的协议（JSON-RPC over Stdio/SSE）与外部工具进程通信。 启示：把工具外部化成服务，是未来 agent 生态的方向（类似 Claude Desktop 源码示例与逐行解析：\nimport asyncio from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams async def main(): client = OpenAIChatCompletionClient(model=\"gpt-4o\") # [1. 配置 MCP 服务器参数] # 这是一个独立的进程。假设我们安装了一个叫 'fetch-mcp' 的工具，能抓取网页 # 相当于我们买了一个“USB设备” server_params = StdioServerParams( command=\"uvx\", # 使用 uvx 运行命令 (Python包管理工具) args=[\"mcp-server-fetch\"] # 具体的 MCP Server 包名 ) # [2. 启动工作台 (McpWorkbench)] # async with 相当于把插头插上，通电 async with McpWorkbench(server_params) as workbench: # [3. 创建 Agent 并把 workbench 给他] # 我们不需要定义 tool 列表，workbench 会自动读取 MCP Server 里有什么工具 # 并自动喂给 Agent agent = AssistantAgent( \"web_surfer\", model_client=client, tools=[workbench], # 直接把整个工具台给它 system_message=\"你可以使用工具来抓取网页内容。\" ) # [4. 运行] # Agent 会自动发现 workbench 里有个 'fetch' 工具，并调用它 await Console(agent.run_stream(task=\"抓取 https://example.com 的内容并总结\")) if __name__ == \"__main__\": asyncio.run(main()) McpWorkbench（网页浏览神器，基于 MCP 协议）\nimport asyncio # 核心组件导入 from autogen_agentchat.agents import AssistantAgent from autogen_agentchat.ui import Console from autogen_ext.models.openai import OpenAIChatCompletionClient # MCP 相关（Model Context Protocol） from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams # MCP 客户端和工作台 async def main() -\u003e None: # 第1步：定义怎么启动 Playwright MCP 服务器（只需要全局安装一次） # 你需要在终端先执行一次：npm install -g @playwright/mcp@latest server_params = StdioServerParams( command=\"npx\", # 用 npx 启动 args=[\"@playwright/mcp@latest\", \"--headless\"], # 参数：最新版 + 无头模式 ) # 第2步：用 async with 自动启动和关闭 MCP 服务器（用完自动杀进程） async with McpWorkbench(server_params) as mcp: # mcp 就是一堆网页工具的集合 # 创建 OpenAI 客户端 client = OpenAIChatCompletionClient(model=\"gpt-4o\") # 创建一个会浏览网页的 Agent agent = AssistantAgent( name=\"web_surfer\", model_client=client, workbench=mcp, # 重点！把 MCP 工具注入给 Agent max_tool_iterations=20, # 最多允许调用 20 次工具（防止死循环） ) # 第3步：让它去干活——打开 GitHub 页面并读取 star 数 await Console(agent.run_stream( task=\"打开 https://github.com/microsoft/autogen ，告诉我这个仓库当前有多少个 star？\" )) # Agent 会： # 1. 调用 MCP 的 open_url 工具打开页面 # 2. 调用 screenshot 或 get_element 工具找 star 按钮 # 3. 提取数字并返回给你 # 启动程序 asyncio.run(main()) 总结：它们给开发者带来了什么？ 功能 关键词 给开发者带来了什么？ 适合场景 GraphFlow 流程图 像画流程图一样写代码，逻辑极其清晰，不再是一团乱麻。 复杂的业务审批流、条件分支任务。 Magentic-One 全能团队 开箱即用的“超级员工”，不用自己设计团队结构，直接解决难题。 复杂通用任务（如“做个市场调研PPT”）。 Swarm 自动转接 去中心化，让对话更自然，Agent 之间配合更像人类同事。 客户服务系统、多角色扮演游戏。 McpWorkbench USB接口 拥有海量现成工具库（Github/Slack/Drive等），即插即用。 需要操作外部软件、读取本地文件的 Agent。 ","wordCount":"3489","inLanguage":"en","datePublished":"2025-11-22T12:35:00+08:00","dateModified":"2025-11-22T12:35:00+08:00","author":{"@type":"Person","name":"您的姓名"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://ljj1992.fun/posts/autogen/"},"publisher":{"@type":"Organization","name":"star徐的博客","logo":{"@type":"ImageObject","url":"http://ljj1992.fun/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://ljj1992.fun/ accesskey=h title="star徐的博客 (Alt + H)">star徐的博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://ljj1992.fun/ title=首页><span>首页</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://ljj1992.fun/>Home</a>&nbsp;»&nbsp;<a href=http://ljj1992.fun/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">AutoGen小白篇(Windows)</h1><div class=post-meta><span title='2025-11-22 12:35:00 +0800 +0800'>November 22, 2025</span>&nbsp;·&nbsp;<span>您的姓名</span></div></header><div class=post-content><h1 id=autogen小白篇windows>AutoGen小白篇(Windows)<a hidden class=anchor aria-hidden=true href=#autogen小白篇windows>#</a></h1><h2 id=1-什么是-autogen它解决了什么痛点>1. 什么是 AutoGen？它解决了什么痛点？<a hidden class=anchor aria-hidden=true href=#1-什么是-autogen它解决了什么痛点>#</a></h2><p>AutoGen 是一个开源框架，用于构建多代理（multi-agent）AI 应用程序，这些代理可以自主行动或与人类协作。根据提供的文档和 GitHub 仓库（https://github.com/microsoft/autogen），AutoGen 旨在简化 AI 代理系统的开发，支持从简单聊天代理到复杂分布式系统的构建。它由 Microsoft xAI 团队开发，支持 Python 和 .NET 等语言，强调事件驱动的编程模型、异步消息传递和可扩展性</p><p>从我的理解来看，AutoGen 不仅仅是一个库，而是一个生态系统，包括核心框架、扩展工具和开发者工具（如 AutoGen Studio）。它允许开发者创建 AI 代理，这些代理可以处理任务如代码生成、网页浏览、数学计算等，通过事件和消息进行协作。相比传统单代理系统，AutoGen 专注于多代理协作，类似于一个“AI 团队”来解决问题。</p><h3 id=核心定义>核心定义<a hidden class=anchor aria-hidden=true href=#核心定义>#</a></h3><p>它不仅仅是一个调用 LLM（大语言模型）的工具，而是一个<strong>协作平台</strong>。它允许你创建多个“角色”（Agents），这些角色可以相互对话、分工合作、调用工具，甚至可以让人类参与其中。</p><h3 id=解决的痛点>解决的痛点<a hidden class=anchor aria-hidden=true href=#解决的痛点>#</a></h3><ol><li><strong>单打独斗的局限性</strong>：单个 ChatGPT 只能回答问题，难以完成复杂任务（如“写代码并运行测试，如果报错则修复”）。AutoGen 让一个负责写，一个负责审，形成闭环。</li><li><strong>上下文管理难</strong>：在长任务中，手动管理对话历史很痛苦。AutoGen 自动处理多轮对话的上下文。</li><li><strong>工具集成繁琐</strong>：让 AI 浏览网页、执行 Python 代码通常需要大量胶水代码。AutoGen 提供了标准化的工具接口（如 MCP Server）。</li><li><strong>扩展性差</strong>：旧的 Agent 框架难以跨语言或跨网络分布。v0.4 引入了“事件驱动”架构，支持分布式部署。</li></ol><h2 id=2-核心特点与架构组成-核心分析>2. 核心特点与架构组成 (核心分析)<a hidden class=anchor aria-hidden=true href=#2-核心特点与架构组成-核心分析>#</a></h2><p>AutoGen v0.4 的设计理念是 <strong>“异步、事件驱动、分布式”</strong>。</p><h3 id=21-架构分层>2.1 架构分层<a hidden class=anchor aria-hidden=true href=#21-架构分层>#</a></h3><h4 id=autogen-的架构是分层的可扩展的基于发布-订阅模型核心组件包括><strong>AutoGen 的架构是分层的</strong>、可扩展的，基于发布-订阅模型。核心组件包括：<a hidden class=anchor aria-hidden=true href=#autogen-的架构是分层的可扩展的基于发布-订阅模型核心组件包括>#</a></h4><ul><li><strong>代理（Agents）</strong>：基本单元，处理事件、调用模型、访问内存或工具。每个代理有事件处理器（Event Handlers），响应特定事件类型。</li><li><strong>事件（Events）</strong>：使用 CloudEvents 格式，包括 ID、源和类型。系统内置事件如系统事件（启动/停止代理）。</li><li><strong>主题（Topics）</strong>：代理订阅主题以接收消息。主题 ID 包括类型和源，支持匹配和映射到代理。</li><li><strong>服务（Services）</strong>：包括 Worker（托管代理）、Gateway（RPC 和事件桥接）、Registry（代理注册）、AgentState（持久状态）和 Routing（事件路由）。</li><li><strong>后端选项</strong>：内存、Python 服务、Microsoft Orleans（分布式演员系统）。</li></ul><p>整体架构：代理通过 Worker 连接服务，事件在服务间流动。分布式时，使用 gRPC 通信。</p><h4 id=对autogen的大白话解释><strong>对AutoGen的大白话解释</strong><a hidden class=anchor aria-hidden=true href=#对autogen的大白话解释>#</a></h4><p><strong>AutoGen 就像一个“AI 客服呼叫中心”：</strong></p><ul><li>代理 = 每一个坐席客服</li><li>事件 = 客户打进来的电话（带着“谁打的、什么事”）</li><li>主题 = 呼叫中心的分机号（比如“技术支持 8001”“退货 8002”）</li><li>服务 = 后勤部门（总机、调度室、档案室、数据库） 整个系统靠“电话铃响了谁接”而不是“你去叫张三来接电话”来运转，这就是发布-订阅的本质。</li></ul><p>下面用一个真实的呼叫中心来彻底讲明白 AutoGen 的每一层。</p><h5 id=1-代理agents-真正干活的客服小哥哥小姐姐>1. 代理（Agents）—— 真正干活的客服小哥哥小姐姐<a hidden class=anchor aria-hidden=true href=#1-代理agents-真正干活的客服小哥哥小姐姐>#</a></h5><ul><li><strong>大白话</strong>：每个代理就是一个会用大模型思考的“智能员工”。你给他发消息，他就能看、思考、回话、打电话（调用工具）、写笔记（改内存）。</li><li><strong>原理</strong>：他们不主动找活干，只听电话铃（事件）。铃声一响，匹配到自己的分机号，就开始处理。</li><li>真实例子<ul><li>写手代理：专门写文章</li><li>代码代理：专门写代码</li><li>浏览网页代理：专门上网查东西</li><li>审查代理：专门挑毛病</li></ul></li></ul><h5 id=2-事件events-客户打进来的每一通电话>2. 事件（Events）—— 客户打进来的每一通电话<a hidden class=anchor aria-hidden=true href=#2-事件events-客户打进来的每一通电话>#</a></h5><ul><li><strong>大白话</strong>：一张标准工单，上面写清楚： “谁打的（source）” + “什么事（type）” + “具体内容（data）” + “工单编号（id）” 这就是 CloudEvents 格式，全国客服中心都认这个标准。</li><li><strong>真实例子</strong>： 你问：“帮我写一个神经网络” → 系统立刻生成一张工单： type = “用户提问” source = “你” data = “帮我写一个神经网络” id = “uuid-12345”</li></ul><h5 id=3-主题topics-呼叫中心的分机号和转接规则>3. 主题（Topics）—— 呼叫中心的分机号和转接规则<a hidden class=anchor aria-hidden=true href=#3-主题topics-呼叫中心的分机号和转接规则>#</a></h5><ul><li><strong>大白话</strong>：就像你拨打客服电话： 技术问题按1 → 转到技术组 退货按2 → 转到售后组 代理提前登记“我能接1号分机”，电话一来自动转过去。</li><li>两个关键概念<ul><li>type（主题类型）：比如 “编程问题”</li><li>source（来源）：可以是具体用户、具体对话ID 组合起来就是完整分机号：编程问题 + 来自用户张三 → 只转给张三专属的编程代理</li></ul></li></ul><h5 id=4服务services-呼叫中心的后勤部门你平时看不到但离了不行>4.服务（Services）—— 呼叫中心的后勤部门（你平时看不到但离了不行<a hidden class=anchor aria-hidden=true href=#4服务services-呼叫中心的后勤部门你平时看不到但离了不行>#</a></h5><table><thead><tr><th>服务名字</th><th>呼叫中心比喻</th><th>实际干啥</th></tr></thead><tbody><tr><td>Worker</td><td>客服工位</td><td>真正跑代理代码的电脑进程</td></tr><tr><td>Gateway</td><td>总机姐姐</td><td>收发所有电话，决定打给哪个工位</td></tr><tr><td>Registry</td><td>花名册</td><td>记录“哪个代理能接什么分机”</td></tr><tr><td>Routing</td><td>智能转接系统</td><td>根据分机号把电话精准送到对应代理</td></tr><tr><td>AgentState</td><td>员工档案柜</td><td>保存每个代理的记忆（上文、历史对话）</td></tr></tbody></table><h5 id=5后端选项-呼叫中心可以开一家小店也可以开全国连锁>5.后端选项—— 呼叫中心可以开一家小店，也可以开全国连锁<a hidden class=anchor aria-hidden=true href=#5后端选项-呼叫中心可以开一家小店也可以开全国连锁>#</a></h5><table><thead><tr><th>后端类型</th><th>比喻</th><th>适合场景</th></tr></thead><tbody><tr><td>内存（In-Memory）</td><td>你家客厅开个2人小呼叫中心</td><td>玩玩、调试、写脚本</td></tr><tr><td>Python 服务</td><td>市中心一间办公室</td><td>小团队用</td></tr><tr><td>Microsoft Orleans</td><td>全国连锁呼叫中心 + 云调度</td><td>上千人同时用、生产环境</td></tr><tr><td>gRPC</td><td>不同城市办公室之间的电话专线</td><td>分布式部署</td></tr></tbody></table><h5 id=完整工作流程用你之前的多代理例子来说>完整工作流程（用你之前的多代理例子来说）<a hidden class=anchor aria-hidden=true href=#完整工作流程用你之前的多代理例子来说>#</a></h5><p>你问：“帮我用Python从零写一个神经网络”</p><ol><li>系统生成一张工单（事件）</li><li>工单扔到“编程问题”这个总机号（主题）</li><li>两个分析代理早就登记了“我能接编程问题” → 同时接到电话（并行！）</li><li>分析代理1（追求高效）开始写答案</li><li>分析代理2（追求简单）也开始写答案</li><li>两个答案写完后，再生成新工单扔给“优化总结”分机</li><li>优化代理接到后，把两份答案对比、补漏、排版成Markdown → 给你</li></ol><p>整个过程没有“你去叫谁”，全靠“铃响了谁接”，这就是发布-订阅（<strong>观察者模式</strong>）的灵魂。</p><h3 id=22-关键概念>2.2 关键概念<a hidden class=anchor aria-hidden=true href=#22-关键概念>#</a></h3><ul><li><strong>Agent (智能体)</strong>：具有特定角色（如“程序员”、“产品经理”）。<ul><li><em>ID</em>: 由 namespace (命名空间) 和 name 组成。</li></ul></li><li><strong>Topic (话题)</strong>：Agent 订阅话题来接收消息（类似消息队列）。</li><li><strong>Lifecycle (生命周期)</strong>：Agent 并不是一直活着的。当有消息发给它时，系统会激活它；闲置时可能会休眠。</li></ul><h3 id=23-使用原理>2.3 使用原理<a hidden class=anchor aria-hidden=true href=#23-使用原理>#</a></h3><p>AutoGen 的核心原理是**发布-订阅（Pub-Sub）**模型结合事件驱动架构：</p><ul><li>代理订阅感兴趣的事件主题。</li><li>当事件发布时，匹配订阅的代理处理它，可能触发新事件或调用工具（如 LLM、网页浏览）。</li><li>对于 RPC 等模式，在事件上层构建请求/响应。</li><li>代理生命周期：按需激活，无需显式创建/销毁。</li><li>数据流：事件携带上下文，代理可修改状态、调用外部 API 或发出新事件。</li></ul><p>原理优势：解耦代理，易于扩展和调试。结合 LLM（如 OpenAI），代理可生成智能响应。</p><h4 id=autogen代理如何判断我对这个事件感兴趣>AutoGen代理如何判断“我对这个事件感兴趣”？<a hidden class=anchor aria-hidden=true href=#autogen代理如何判断我对这个事件感兴趣>#</a></h4><p><strong>关键点：流程说明</strong></p><ul><li>代理自己提前“登记”感兴趣的分机号（订阅主题）。</li><li>每来一个事件（电话），系统就看事件的分机号（TopicId）和自己登记的分机号对不对得上。</li><li>对得上 → 感兴趣 → 接电话！对不上 → 完全忽略。</li><li>匹配方式超级灵活：可以精确匹配，也可以“*通配符”批量匹配。</li></ul><p>下面用最接地气的例子给你讲明白。</p><hr><p><strong>用“客服呼叫中心”再讲一遍（你已经熟悉这个比喻了）</strong></p><ol><li>代理提前去总机登记：<ul><li>代码代理说：“我能接所有 type=编程问题 的电话！”</li><li>数学代理说：“我只接 type=数学计算:* 的电话（*表示不管是谁打的都接）”</li><li>用户专属代理说：“我只接 type=用户提问 AND source=用户张三 的电话”</li></ul></li><li>用户打进来一个电话（事件） 事件内容： type = “编程问题” source = “用户张三”</li><li>系统（Routing服务）立刻拿这张工单去比对所有代理的登记表：<ul><li>代码代理登记的是 “编程问题” → 完全匹配 → 响铃！</li><li>数学代理登记的是 “数学计算” → 不匹配 → 不响铃</li><li>用户专属代理登记的是 “编程问题 + 用户张三” → 也匹配 → 也响铃！</li></ul></li><li>结果：代码代理和用户专属代理同时接到这个任务（可以并行干活）</li></ol><p>这就是整个匹配过程！</p><table><thead><tr><th>函数</th><th>大白话名字</th><th>作用</th><th>举例</th></tr></thead><tbody><tr><td>Matcher</td><td>“我感不感兴趣”</td><td>输入一个事件TopicId → 返回 True / False</td><td>Matcher = lambda topic: topic.type.startswith(&ldquo;编程&rdquo;)</td></tr><tr><td>Mapper</td><td>“转给我哪个工位”</td><td>如果感兴趣了，把这个事件转给具体哪个代理实例</td><td>Mapper = lambda topic: AgentId(type=&ldquo;代码代理&rdquo;, key=topic.source)</td></tr></tbody></table><p>代码长这样（真实Python写法）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 代码代理订阅所有编程问题（用通配符 * 表示“我全都要”）</span>
</span></span><span style=display:flex><span>subscription <span style=color:#f92672>=</span> Subscription(
</span></span><span style=display:flex><span>    matcher<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> topic: topic<span style=color:#f92672>.</span>type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;编程问题&#34;</span>,           <span style=color:#75715e># 精确匹配type</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># matcher=lambda topic: &#34;编程&#34; in topic.type             # 模糊包含也行</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># matcher=lambda topic: topic.type.startswith(&#34;com.ai.&#34;) # 前缀匹配也行</span>
</span></span><span style=display:flex><span>    mapper<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> topic: AgentId(type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;代码代理&#34;</span>, key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;default&#34;</span>)  <span style=color:#75715e># 都转给同一个默认实例</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 数学代理用通配符订阅所有数学相关</span>
</span></span><span style=display:flex><span>subscription2 <span style=color:#f92672>=</span> Subscription(
</span></span><span style=display:flex><span>    matcher<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> topic: topic<span style=color:#f92672>.</span>type<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#34;数学计算:&#34;</span>),  <span style=color:#75715e># :后面是source，随便</span>
</span></span><span style=display:flex><span>    mapper<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> topic: AgentId(type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;数学代理&#34;</span>, key<span style=color:#f92672>=</span>topic<span style=color:#f92672>.</span>source<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;:&#34;</span>)[<span style=color:#ae81ff>1</span>])  <span style=color:#75715e># 按来源动态创建不同实例</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p><strong>支持的匹配方式汇总（超级灵活！）</strong></p><table><thead><tr><th>匹配方式</th><th>代码例子</th><th>大白话解释</th></tr></thead><tbody><tr><td>完全相等</td><td>topic.type == &ldquo;编程问题&rdquo;</td><td>分机号一模一样才接</td></tr><tr><td>前缀匹配</td><td>topic.type.startswith(&ldquo;com.microsoft.&rdquo;)</td><td>所有微软内部事件都接</td></tr><tr><td>包含关键词</td><td>&ldquo;数学&rdquo; in topic.type</td><td>只要提到数学我就接</td></tr><tr><td>通配符 *</td><td>topic.type == &ldquo;用户提问:*&rdquo;</td><td>所有用户提问我都接，不管是谁</td></tr><tr><td>正则表达式</td><td>re.match(r"编程\d+", topic.type)</td><td>编程1、编程2、编程123 都接</td></tr><tr><td>组合条件</td><td>topic.type == &ldquo;编程问题&rdquo; and topic.source == &ldquo;张三&rdquo;</td><td>只有张三的编程问题我才接</td></tr></tbody></table><p><strong>实际运行时发生了什么（一步一步）</strong></p><ol><li>代理启动时，把自己的 Matcher 和FD Mapper 函数注册到 Registry（花名册）</li><li>有人发布一个事件 → Routing 服务拿到事件</li><li>Routing 遍历所有订阅：<ul><li>挨个调用每个代理的 matcher(event)</li><li>返回 True 的代理全被叫醒</li><li>再用 mapper(event) 决定具体转给哪个实例（可能动态创建新实例！）</li></ul></li><li>事件被送到对应代理的“事件处理器”里执行</li></ol><h4 id=autogen订阅机制真实运行示例>AutoGen订阅机制真实运行示例<a hidden class=anchor aria-hidden=true href=#autogen订阅机制真实运行示例>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#f92672>import</span> asyncio  <span style=color:#960050;background-color:#1e0010>#</span> 引入异步库<span style=color:#960050;background-color:#1e0010>，</span>让程序可以<span style=color:#960050;background-color:#1e0010>“</span>同时等多个电话<span style=color:#960050;background-color:#1e0010>”</span>而不卡住
</span></span></code></pre></div><p>观察者模式思维：整个系统是异步事件驱动的，代理像“客服在座位上等铃响”，不用自己不停问“有没有活”。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>from autogen_core.<span style=color:#a6e22e>base</span> <span style=color:#f92672>import</span> MessageContext  <span style=color:#960050;background-color:#1e0010>#</span> 消息上下文<span style=color:#960050;background-color:#1e0010>，</span>事件到来时会带上
</span></span><span style=display:flex><span>from autogen_core.<span style=color:#a6e22e>components</span> <span style=color:#f92672>import</span> DefaultTopicPubSub, RoutedAgent, message_handler
</span></span><span style=display:flex><span>from autogen_core.<span style=color:#a6e22e>application</span> <span style=color:#f92672>import</span> SingleThreadedAgentRuntime  <span style=color:#960050;background-color:#1e0010>#</span> 单线程运行时<span style=color:#960050;background-color:#1e0010>（</span>本地调试用<span style=color:#960050;background-color:#1e0010>）</span>
</span></span></code></pre></div><p><strong>观察者模式思维</strong>：</p><ul><li>RoutedAgent = 可订阅的观察者（Observer）</li><li>DefaultTopicPubSub = 主题总线（Subject）</li><li>message_handler = 观察者收到通知后执行的方法</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>#</span> 1. 定义一个<span style=color:#960050;background-color:#1e0010>“</span>代码代理<span style=color:#960050;background-color:#1e0010>”——</span>观察者本人
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CodeWriterAgent</span>(RoutedAgent):  <span style=color:#960050;background-color:#1e0010>#</span> 继承RoutedAgent<span style=color:#960050;background-color:#1e0010>，</span>表示它能被路由<span style=color:#960050;background-color:#1e0010>（</span>能订阅<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex><span>    def <span style=color:#a6e22e>__init__</span>(self, description: str):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>super</span>().<span style=color:#a6e22e>__init__</span>(description)  <span style=color:#960050;background-color:#1e0010>#</span> 初始化父类<span style=color:#960050;background-color:#1e0010>，</span>告诉系统<span style=color:#960050;background-color:#1e0010>“</span>我是一个可订阅的代理<span style=color:#960050;background-color:#1e0010>”</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#960050;background-color:#1e0010>#</span> 装饰器<span style=color:#960050;background-color:#1e0010>：</span>当收到匹配的事件时<span style=color:#960050;background-color:#1e0010>，</span>自动调用这个方法<span style=color:#960050;background-color:#1e0010>（</span>这就是观察者被通知<span style=color:#960050;background-color:#1e0010>！）</span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@message_handler</span>
</span></span><span style=display:flex><span>    async def <span style=color:#a6e22e>handle_user_message</span>(self, message: dict, ctx: MessageContext):
</span></span><span style=display:flex><span>        print(f<span style=color:#e6db74>&#34;【代码代理收到任务】用户说：{message[&#39;content&#39;]}&#34;</span>)
</span></span><span style=display:flex><span>        reply <span style=color:#f92672>=</span> f<span style=color:#e6db74>&#34;我来写代码啦！这里是解决方案：\n```python\n# 示例代码\ndef hello():\n    print(&#39;Hello from AutoGen!&#39;)\n```&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#960050;background-color:#1e0010>#</span> 把结果发回给原来的主题<span style=color:#960050;background-color:#1e0010>（</span>相当于回电话<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex><span>        await self.<span style=color:#a6e22e>publish_message</span>({<span style=color:#e6db74>&#34;content&#34;</span>: reply}, topic_id<span style=color:#f92672>=</span>ctx.<span style=color:#a6e22e>topic_id</span>)
</span></span></code></pre></div><p><strong>观察者模式核心在这里</strong>：</p><ul><li>@message_handler = “我注册了一个观察方法”</li><li>当系统发现事件匹配时，自动调用这个方法 → <strong>被观察者（Subject）主动通知观察者（Observer）</strong></li><li>代理完全不知道谁发的消息，只管处理 → 完美解耦</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>async def <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    <span style=color:#960050;background-color:#1e0010>#</span> 2. 创建运行时 <span style=color:#f92672>=</span> 创建<span style=color:#960050;background-color:#1e0010>“</span>事件总线<span style=color:#960050;background-color:#1e0010>”（</span>被观察者<span style=color:#f92672>/</span>Subject<span style=color:#960050;background-color:#1e0010>）</span>
</span></span><span style=display:flex><span>    runtime <span style=color:#f92672>=</span> SingleThreadedAgentRuntime()
</span></span></code></pre></div><p>观察者模式思维：runtime 就是整个系统的“大脑”，负责维护“谁订阅了什么”。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>#</span> 3. 注册代理 <span style=color:#f92672>+</span> 订阅主题 <span style=color:#960050;background-color:#1e0010>——</span> 这就是观察者向被观察者注册<span style=color:#960050;background-color:#1e0010>！</span>
</span></span><span style=display:flex><span>    await CodeWriterAgent.<span style=color:#a6e22e>register</span>(
</span></span><span style=display:flex><span>        runtime,                                   <span style=color:#960050;background-color:#1e0010>#</span> 把代理注册到总线
</span></span><span style=display:flex><span>        type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;code_writer&#34;</span>,                        <span style=color:#960050;background-color:#1e0010>#</span> 代理类型名称
</span></span><span style=display:flex><span>        factory<span style=color:#f92672>=</span>lambda: CodeWriterAgent(<span style=color:#e6db74>&#34;我是一个专业的代码生成代理&#34;</span>),  <span style=color:#960050;background-color:#1e0010>#</span> 如何创建实例
</span></span><span style=display:flex><span>        subscriptions<span style=color:#f92672>=</span>lambda topic: topic.<span style=color:#a6e22e>type</span> <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;programming_task&#34;</span>  <span style=color:#960050;background-color:#1e0010>#</span> <span style=color:#960050;background-color:#1e0010>←</span> 关键<span style=color:#960050;background-color:#1e0010>！</span>订阅规则
</span></span><span style=display:flex><span>    )
</span></span></code></pre></div><p><strong>逐行拆解 subscriptions=lambda topic: topic.type == &ldquo;programming_task&rdquo;</strong></p><ul><li>这是一个<strong>Matcher 函数</strong>（判断“我感不感兴趣”）</li><li>每当有新事件到来，系统会遍历所有已注册的代理，调用这个 lambda</li><li>如果返回 True → “铃响了！这个代理要被唤醒”</li><li><strong>这就是观察者模式中最经典的“注册兴趣”步骤</strong>！</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>#</span> 4. 启动默认的发布<span style=color:#f92672>-</span>订阅总线
</span></span><span style=display:flex><span>    DefaultTopicPubSub.<span style=color:#a6e22e>register</span>(runtime)
</span></span></code></pre></div><p>观察者模式思维：激活总线，现在所有订阅都生效了。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>runtime.<span style=color:#a6e22e>start</span>()  <span style=color:#960050;background-color:#1e0010>#</span> 启动运行时<span style=color:#960050;background-color:#1e0010>，</span>开始监听事件
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>print</span>(<span style=color:#e6db74>&#34;系统已启动，代码代理正在等待编程任务...&#34;</span>)
</span></span></code></pre></div><p>观察者模式思维：代理现在坐在工位上，耳朵竖着等铃响</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>#</span> 5. 模拟用户发布一个事件 <span style=color:#960050;background-color:#1e0010>——</span> 相当于<span style=color:#960050;background-color:#1e0010>“</span>有人打进电话<span style=color:#960050;background-color:#1e0010>”</span>
</span></span><span style=display:flex><span>    await runtime.<span style=color:#a6e22e>publish_message</span>(
</span></span><span style=display:flex><span>        {<span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;帮我写一个Python快速排序&#34;</span>},
</span></span><span style=display:flex><span>        topic_id<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;programming_task&#34;</span>, <span style=color:#e6db74>&#34;source&#34;</span>: <span style=color:#e6db74>&#34;user123&#34;</span>}  <span style=color:#960050;background-color:#1e0010>#</span> 事件的分机号
</span></span><span style=display:flex><span>    )
</span></span></code></pre></div><p><strong>观察者模式关键时刻</strong>：</p><ol><li>事件发布 → 总线收到</li><li>总线遍历所有订阅 → 调用 lambda → 返回 True</li><li>自动把事件路由给 CodeWriterAgent</li><li>@message_handler 方法被调用 → 打印“收到任务” → 回复代码</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>await asyncio.<span style=color:#a6e22e>sleep</span>(2)  <span style=color:#960050;background-color:#1e0010>#</span> 等待2秒看结果
</span></span><span style=display:flex><span>    await runtime.<span style=color:#a6e22e>stop</span>()     <span style=color:#960050;background-color:#1e0010>#</span> 停止系统
</span></span></code></pre></div><p>完整运行逻辑图（观察者模式视角）</p><table><thead><tr><th>角色</th><th>代码对应部分</th><th>观察者模式术语</th></tr></thead><tbody><tr><td>被观察者（Subject）</td><td>runtime + DefaultTopicPubSub</td><td>事件总线</td></tr><tr><td>观察者（Observer）</td><td>CodeWriterAgent</td><td>代码代理</td></tr><tr><td>注册观察</td><td>CodeWriterAgent.register(&mldr;, subscriptions=&mldr;)</td><td>attach(observer)</td></tr><tr><td>发布事件</td><td>runtime.publish_message(&mldr;)</td><td>notify()</td></tr><tr><td>收到通知</td><td>@message_handler 方法被调用</td><td>update()</td></tr></tbody></table><p><strong>总结一句话</strong></p><p>“代理订阅 = 观察者提前告诉系统‘这种电话我接’，事件发布 = 被观察者喊一声‘来电话啦！’，系统自动遍历所有观察者，问一遍‘你接吗？’，回答‘接’的就自动被叫醒干活 —— 整个过程代理之间互不认识，完全靠系统自动通知，这才是真正的观察者模式！”</p><h3 id=技术原理解释matcher-函数和-mapper-函数>技术原理解释（Matcher 函数和 Mapper 函数）<a hidden class=anchor aria-hidden=true href=#技术原理解释matcher-函数和-mapper-函数>#</a></h3><p>AutoGen文档里写了两个核心函数，就是“判断感兴趣”和“转给谁”的关键：</p><h3 id=24-实际使用场景>2.4 实际使用场景<a hidden class=anchor aria-hidden=true href=#24-实际使用场景>#</a></h3><ul><li><strong>自动化任务</strong>：如代码审查（一个代理生成代码，另一个审查）。</li><li><strong>研究与数据分析</strong>：多代理协作查询数学、化学问题，或浏览网页获取实时信息。</li><li><strong>聊天机器人</strong>：构建多代理聊天系统，一个代理处理用户输入，另一个调用工具。</li><li><strong>分布式 AI 系统</strong>：在云环境中部署代理团队处理大规模数据。</li><li><strong>游戏/模拟</strong>：代理模拟角色互动。</li><li><strong>企业应用</strong>：如客服系统，多代理分工处理查询。</li></ul><p>案例：在 README 中，展示网页浏览代理查询 GitHub 贡献者，或多代理处理数学/化学查询。</p><h3 id=25-功能模块说明>2.5 功能模块说明<a hidden class=anchor aria-hidden=true href=#25-功能模块说明>#</a></h3><table><thead><tr><th>模块名称</th><th>作用</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>autogen-core</strong></td><td>提供消息总线、事件处理、RPC。</td><td>高级开发，需要构建分布式、跨语言 Agent 系统。</td></tr><tr><td><strong>autogen-agentchat</strong></td><td>提供 AssistantAgent, UserProxy 等高级封装。</td><td><strong>新手推荐</strong>。构建聊天机器人、任务编排。</td></tr><tr><td><strong>autogen-ext</strong></td><td>提供模型客户端（OpenAI/Azure）和工具（MCP）。</td><td>连接大模型 API，连接外部工具（浏览器、终端）。</td></tr><tr><td><strong>AutoGen Studio</strong></td><td>无代码/低代码的可视化界面。</td><td>演示、原型设计，不想写代码时使用。</td></tr></tbody></table><p>你可以把 <strong>AutoGen</strong> 想象成你在组装一台 <strong>“超级电脑”</strong> 或者经营一家 <strong>“AI 公司”</strong>。为了让这个系统灵活好用，微软把代码拆成了四个不同的零件包。</p><p>我用<strong>大白话 + “开公司”的例子</strong>给你逐一解释：</p><hr><p>没问题！作为一个刚接触的新手，看到这些带横杠的英文包名确实容易晕。</p><p>你可以把 <strong>AutoGen</strong> 想象成你在组装一台 <strong>“超级电脑”</strong> 或者经营一家 <strong>“AI 公司”</strong>。为了让这个系统灵活好用，微软把代码拆成了四个不同的零件包。</p><p>我用<strong>大白话 + “开公司”的例子</strong>给你逐一解释：</p><hr><h4 id=1-autogen-core--公司的地基和电话线>1. autogen-core —— 公司的地基和电话线<a hidden class=anchor aria-hidden=true href=#1-autogen-core--公司的地基和电话线>#</a></h4><ul><li><strong>别名</strong>：核心底层</li><li><strong>大白话原理</strong>：
这是最底层的东西，你平时写代码可能很少直接用到它，但没它不行。它负责<strong>脏活累活</strong>，比如：<ul><li>保证 Agent A 发的消息，Agent B 能收到。</li><li>如果 Agent 很多，它负责安排谁在哪个进程里运行。</li><li>它定义了大家沟通的“语言标准”（事件）。</li></ul></li><li><strong>比喻</strong>：
这就是公司的<strong>办公大楼、电话线路和会议室</strong>。它不干具体的业务，但提供了员工（Agent）工作的物理场所和沟通渠道。没有它，员工没法上班，也没法打电话。</li></ul><h4 id=2-autogen-agentchat--公司的员工和管理制度-新手最常用>2. autogen-agentchat —— 公司的员工和管理制度 【新手最常用】<a hidden class=anchor aria-hidden=true href=#2-autogen-agentchat--公司的员工和管理制度-新手最常用>#</a></h4><ul><li><strong>别名</strong>：聊天代理层（应用层）</li><li><strong>大白话原理</strong>：
这是你<strong>90%的时间都在打交道</strong>的部分。这里面封装好了各种现成的“员工模板”。<ul><li>你想造一个会写代码的 AI？用这里的 AssistantAgent。</li><li>你想造一个代表用户的 AI？用这里的 UserProxy。</li><li>你想让两个 AI 聊天？用这里的代码把它们连起来。</li></ul></li><li><strong>比喻</strong>：
这就是公司的<strong>招聘启事和员工手册</strong>。
你通过它来定义：“你是程序员，叫小王”、“你是产品经理，叫小李”。你在这里指挥他们干活。
<strong>新手写代码，主要就是 import 这个包里的东西。</strong></li></ul><h4 id=3-autogen-ext--员工的外部工具包>3. autogen-ext —— 员工的外部工具包<a hidden class=anchor aria-hidden=true href=#3-autogen-ext--员工的外部工具包>#</a></h4><ul><li><strong>别名</strong>：扩展包/插件包</li><li><strong>大白话原理</strong>：
AutoGen 本身是个空架子，它得连上大模型（比如 GPT-4）或者外部工具才能干活。<ul><li>你想用 OpenAI 的模型？你需要 autogen-ext[openai]。</li><li>你想用 Azure 的模型？你需要 autogen-ext[azure]。</li><li>你想让 AI 能控制浏览器？你需要这里的 MCP 工具扩展。
之所以把这些拆出来，是因为不想让你安装主程序时，被迫下载一堆你用不到的驱动。</li></ul></li><li><strong>比喻</strong>：
这就是员工的<strong>电脑、软件和外设</strong>。
你招了人（AgentChat），安排了工位（Core），但还没给他们配电脑。如果你想让他们用微软的 Word 干活，你就装个“微软扩展包”；如果你想让他们用谷歌的 Docs，你就装个“谷歌扩展包”。<strong>按需购买，随插随用。</strong></li></ul><h4 id=4-autogen-studio--傻瓜式老板控制台>4. AutoGen Studio —— 傻瓜式老板控制台<a hidden class=anchor aria-hidden=true href=#4-autogen-studio--傻瓜式老板控制台>#</a></h4><ul><li><strong>别名</strong>：可视化界面</li><li><strong>大白话原理</strong>：
这是一个网页界面（UI）。给那些<strong>不想写代码</strong>，或者想快速给老板演示的人用的。<ul><li>你不需要在黑乎乎的命令行里敲代码。</li><li>你在网页上点点鼠标，“拖拽”出一个 Agent，设置它的名字，就能在这个网页里跟它聊天。</li></ul></li><li><strong>比喻</strong>：
这就是<strong>极品飞车游戏的驾驶界面</strong>。
前面的三个（Core/AgentChat/Ext）相当于你在车库里手搓零件造赛车。而 AutoGen Studio 相当于直接给你一个做好的界面，你只需要握着方向盘（鼠标）开就行了，不用管引擎是怎么接线的。</li></ul><hr><h4 id=总结他们之间的关系>总结：他们之间的关系<a hidden class=anchor aria-hidden=true href=#总结他们之间的关系>#</a></h4><p>如果我们要完成一个任务：<strong>“让 AI 帮我写个贪吃蛇游戏”</strong>。</p><ol><li><strong>autogen-core</strong> 在后台默默搭建了消息通道，确保信号畅通。</li><li>你写代码调用 <strong>autogen-agentchat</strong>，创建了一个“程序员 Agent”和一个“测试员 Agent”。</li><li>因为你要用 GPT-4 的智力，所以你安装了 <strong>autogen-ext</strong> 来连接 OpenAI 的 API。</li><li>如果你懒得写代码，你想直接用鼠标点一点就生成游戏，你就打开 <strong>AutoGen Studio</strong>。</li></ol><h4 id=给新手的建议>给新手的建议<a hidden class=anchor aria-hidden=true href=#给新手的建议>#</a></h4><ul><li><strong>如果不写代码，只想玩玩</strong>：直接去研究 <strong>AutoGen Studio</strong>。</li><li><strong>如果是开发人员，想写 Python 代码</strong>：<ul><li>安装时：pip install autogen-agentchat autogen-ext[openai]</li><li>写代码时：主要关注 <strong>autogen-agentchat</strong> 里的写法。</li><li>不用太纠结 <strong>autogen-core</strong>，除非你要搞超级复杂的分布式系统。</li></ul></li></ul><hr><h2 id=安装windows>安装(windows)<a hidden class=anchor aria-hidden=true href=#安装windows>#</a></h2><p>作为 Windows 用户，建议使用 PowerShell 或 VS Code 的终端。</p><h3 id=第一步环境准备>第一步：环境准备<a hidden class=anchor aria-hidden=true href=#第一步环境准备>#</a></h3><p>确保你安装了 <strong>Python 3.10 或更高版本</strong>。
在 CMD 或 PowerShell 中输入 python &ndash;version 检查。</p><h3 id=第二步创建虚拟环境-强烈推荐>第二步：创建虚拟环境 (强烈推荐)<a hidden class=anchor aria-hidden=true href=#第二步创建虚拟环境-强烈推荐>#</a></h3><p>不要把包安装到全局环境，容易冲突。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span><span style=color:#75715e># 1. mkdir (Make Directory) 创建新目录，cd (Change Directory) 切换当前工作目录</span>
</span></span><span style=display:flex><span>mkdir MyAutoGenProject
</span></span><span style=display:flex><span>cd MyAutoGenProject
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. 创建虚拟环境 (venv)，让Python 在这个文件夹里建一个“独立小房间”。以后安装的软件只放在这个小房间里，不会弄脏你电脑的其他地方</span>
</span></span><span style=display:flex><span>python -m venv .venv
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 3. 激活虚拟环境 (Windows PowerShell)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 如果提示权限错误，先运行：Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser</span>
</span></span><span style=display:flex><span>.\.venv\Scripts\Activate
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#如果系统提示“禁止运行脚本”或红色报错，请执行下面这行命令解锁权限，然后再执行上面的激活命令：</span>
</span></span><span style=display:flex><span>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 激活成功后，命令行前面会出现 (.venv) 字样</span>
</span></span></code></pre></div><h3 id=第三步安装-autogen-v04-核心包>第三步：安装 AutoGen v0.4 核心包<a hidden class=anchor aria-hidden=true href=#第三步安装-autogen-v04-核心包>#</a></h3><p>根据参考文件 README (1).md，v0.4 采用了分包策略，不再是以前的一个 pyautogen 包了</p><p><strong>执行安装命令</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span>pip install -U <span style=color:#e6db74>&#34;autogen-agentchat&#34;</span> <span style=color:#e6db74>&#34;autogen-ext[openai]&#34;</span>
</span></span></code></pre></div><p>请仔细看这个命令，我来逐词解释：：</p><ul><li><strong>&ldquo;autogen-agentchat&rdquo;</strong><ul><li><strong>【技术原理】</strong>：安装 AutoGen 的高层应用 API（对应文档中的 AgentChat 层）。</li><li><strong>【大白话】</strong>：这是<strong>主程序</strong>。也就是你要用来创建“助理Agent”、“用户Agent”的核心代码包。注意，v0.4 必须装这个，而不是旧版的 pyautogen。</li></ul></li><li><strong>&ldquo;autogen-ext[openai]&rdquo;</strong><ul><li><strong>【技术原理】</strong>：安装 AutoGen 的扩展包，并指定 openai 作为附加依赖（Extra Dependencies）。</li><li><strong>【大白话】</strong>：这是<strong>配件包</strong>。AutoGen 本身是个空壳，它需要连大模型。这个包里包含了连接 OpenAI（或者兼容 OpenAI 接口的模型，如通义千问、DeepSeek）所需的驱动程序。</li></ul></li></ul><h3 id=第四步配置-api-key-并验证>第四步：配置 API Key 并验证<a hidden class=anchor aria-hidden=true href=#第四步配置-api-key-并验证>#</a></h3><p><strong>设置临时环境变量</strong></p><p>为了验证安装成功，我们需要设置 API Key。在 PowerShell 中输入</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span>$env:OPENAI_API_KEY=<span style=color:#e6db74>&#34;sk-你的密钥放这里&#34;</span>
</span></span></code></pre></div><ul><li><strong>【技术原理】</strong>：在当前 PowerShell 会话中设置名为 OPENAI_API_KEY 的环境变量。</li><li><strong>【大白话】</strong>：告诉电脑：“待会儿如果有程序要查户口（找密钥），就把这串密码给它。”（注意：关掉窗口后这个设置会失效，下次要重新输）。</li></ul><p><strong>创建测试脚本验证</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#75715e># 尝试导入 v0.4 的新包，如果不报错说明安装成功</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;✅ AutoGen v0.4 环境安装成功！&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 简单的创建一个客户端实例测试</span>
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;✅ 客户端创建成功: </span><span style=color:#e6db74>{</span>client<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><h3 id=第五步运行测试>第五步：运行测试<a hidden class=anchor aria-hidden=true href=#第五步运行测试>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>python test_install<span style=color:#f92672>.</span>py
</span></span></code></pre></div><ul><li><strong>【反馈】</strong>：如果屏幕打印出 ✅ AutoGen v0.4 环境安装成功！，恭喜你，你的 Windows 环境已经完美就绪！</li></ul><hr><h3 id=总结老手和新手的区别>总结：老手和新手的区别<a hidden class=anchor aria-hidden=true href=#总结老手和新手的区别>#</a></h3><ul><li><strong>旧版 (v0.2)</strong>：以前大家习惯 pip install pyautogen。</li><li><strong>新版 (v0.4)</strong>：现在是 <strong>模块化安装</strong>。<ul><li>如果你只做普通对话，装 autogen-agentchat。</li><li>如果你要连 OpenAI，加装 autogen-ext[openai]。</li><li>如果你要用 Azure，加装 autogen-ext[azure]。</li></ul></li></ul><h2 id=实战新人如何开始使用-代码案例>实战：新人如何开始使用 (代码案例)<a hidden class=anchor aria-hidden=true href=#实战新人如何开始使用-代码案例>#</a></h2><p>我们从最基础的开始，逐步深入。请在项目目录下创建 .py 文件运行。</p><h3 id=场景一hello-world-单兵作战>场景一：Hello World (单兵作战)<a hidden class=anchor aria-hidden=true href=#场景一hello-world-单兵作战>#</a></h3><p><strong>目标</strong>：创建一个助手，让它说“Hello World”。
<strong>核心类</strong>：AssistantAgent (助理代理), OpenAIChatCompletionClient (模型客户端)。</p><p>创建文件 hello.py:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>() <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># 1. 定义模型客户端 (这里用 gpt-4o 或 gpt-3.5-turbo)</span>
</span></span><span style=display:flex><span>    model_client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 2. 创建一个助手 Agent</span>
</span></span><span style=display:flex><span>    agent <span style=color:#f92672>=</span> AssistantAgent(<span style=color:#e6db74>&#34;my_assistant&#34;</span>, model_client<span style=color:#f92672>=</span>model_client)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 3. 运行任务并打印结果</span>
</span></span><span style=display:flex><span>    print(<span style=color:#66d9ef>await</span> agent<span style=color:#f92672>.</span>run(task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;请用中文向我问好，并写一句关于AI的诗。&#34;</span>))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 4. 关闭客户端</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> model_client<span style=color:#f92672>.</span>close()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><h3 id=场景二多智能体协作-团队作战>场景二：多智能体协作 (团队作战)<a hidden class=anchor aria-hidden=true href=#场景二多智能体协作-团队作战>#</a></h3><p><strong>标</strong>：一个数学专家和一个化学专家，由一个主助手协调回答问题。
<strong>原理</strong>：使用 AgentTool 将一个 Agent 包装成另一个 Agent 的“工具”。这是 v0.4 推荐的简单编排方式。</p><p>创建文件 team.py:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># --- 导入部分 ---</span>
</span></span><span style=display:flex><span><span style=color:#75715e># asyncio 是 Python 用来处理并发任务的标准库。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 简单理解：它可以让程序在等待（比如等待AI回复）的时候不卡死，去处理别的事情。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> asyncio 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 从 autogen_agentchat 库中导入 AssistantAgent。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这是一个通用的 AI 助手类，可以把它看作一个具体的“人”或“角色”。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 导入 AgentTool。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 它的作用是把一个 Agent 包装成一个“工具”，这样其他的 Agent 就可以像调用函数一样调用它。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.tools <span style=color:#f92672>import</span> AgentTool 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 导入 Console。这是一个辅助工具，用来在黑框框（终端）里漂亮地打印出 AI 的对话过程。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 导入 OpenAI 的客户端。这是程序的大脑，负责连接 GPT-4 等模型。</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># --- 主函数定义 ---</span>
</span></span><span style=display:flex><span><span style=color:#75715e># async def 定义了一个异步函数。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 在 Python 中，如果函数内部涉及网络请求（比如问 GPT），通常都要用 async 定义。</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>() <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># 1. 初始化模型客户端</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这里我们配置了使用 &#34;gpt-4o&#34; 模型。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 注意：实际运行通过 api_key 连接，通常从环境变量中自动读取 OPENAI_API_KEY。</span>
</span></span><span style=display:flex><span>    model_client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># --- 2. 创建专员 (子 Agent) ---</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 创建第一个 Agent：数学专家</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># name: 给这个 Agent 起个名字，方便日志区分。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># system_message: &#34;人设&#34;指令，告诉 AI 它该扮演什么角色，只做什么事。</span>
</span></span><span style=display:flex><span>    math_agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;math_expert&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>model_client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是一个数学专家，只回答数学计算问题。&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 【关键步骤】将 Agent 包装成工具</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 正常的 Agent 是用来对话的，但在这里，我们要把它变成主管手中的一个“计算器”。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># return_value_as_last_message=True: 意思是这个工具运行完，直接把最后一句回复作为结果返回给调用者。</span>
</span></span><span style=display:flex><span>    math_tool <span style=color:#f92672>=</span> AgentTool(math_agent, return_value_as_last_message<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 创建第二个 Agent：化学专家</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 逻辑同上，只是人设不同。</span>
</span></span><span style=display:flex><span>    chem_agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chemistry_expert&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>model_client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是一个化学专家，只回答分子式和化学反应问题。&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#75715e># 同样将其包装成工具</span>
</span></span><span style=display:flex><span>    chem_tool <span style=color:#f92672>=</span> AgentTool(chem_agent, return_value_as_last_message<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># --- 3. 创建主控 Agent (Manager) ---</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这个 Agent 是用户直接对话的对象，类似于“包工头”或“前台”。</span>
</span></span><span style=display:flex><span>    manager <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;manager&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e># 它的指令非常重要：告诉它在什么情况下使用什么工具。</span>
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是一个总管。遇到数学问题调用 math_expert，遇到化学问题调用 chemistry_expert。&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>model_client,
</span></span><span style=display:flex><span>        <span style=color:#75715e># tools: 这里把上面做好的两个“工具人”塞给它。</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 当 GPT 判定用户问题需要数学知识时，它就会自动调用 math_tool。</span>
</span></span><span style=display:flex><span>        tools<span style=color:#f92672>=</span>[math_tool, chem_tool], 
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># --- 4. 运行任务 ---</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># task: 这是用户发出的真实指令。包含了一个化学问题和一个数学问题。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># manager.run_stream(...): 让 manager 开始思考并处理任务，以“流式”方式返回（像打字机一样一个字一个字蹦）。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Console(...): 这是一个 UI 包装器，它会自动接收流式数据并漂亮地打印在屏幕上。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># await: 这是一个等待指令，意思是“程序在这里暂停，直到对话完全结束再往下走”。</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> Console(manager<span style=color:#f92672>.</span>run_stream(task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;请告诉我水的分子量是多少？然后算一下 2的10次方是多少？&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># --- 程序入口 ---</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这是 Python 的标准写法。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 如果直接运行这个文件（而不是被别的代码 import），就执行下面的代码。</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># asyncio.run() 是启动异步程序的“钥匙”。</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 它负责创建一个事件循环，并运行 main() 函数。</span>
</span></span><span style=display:flex><span>    asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><hr><h3 id=常用命令与参数速查>常用命令与参数速查<a hidden class=anchor aria-hidden=true href=#常用命令与参数速查>#</a></h3><h3 id=核心类参数说明>核心类参数说明<a hidden class=anchor aria-hidden=true href=#核心类参数说明>#</a></h3><h4 id=assistantagent-最常用的类>AssistantAgent (最常用的类)<a hidden class=anchor aria-hidden=true href=#assistantagent-最常用的类>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;agent_name&#34;</span>,              <span style=color:#75715e># [必填] Agent 的名字，用于标识</span>
</span></span><span style=display:flex><span>    model_client<span style=color:#f92672>=</span>client,            <span style=color:#75715e># [必填] 模型客户端实例</span>
</span></span><span style=display:flex><span>    system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;You are...&#34;</span>,    <span style=color:#75715e># [可选] 系统提示词（人设）</span>
</span></span><span style=display:flex><span>    tools<span style=color:#f92672>=</span>[tool1, tool2],           <span style=color:#75715e># [可选] 该 Agent 可用的工具列表</span>
</span></span><span style=display:flex><span>    description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;描述...&#34;</span>,          <span style=color:#75715e># [可选] 描述该 Agent 能干什么（给其他 Agent 看的）</span>
</span></span><span style=display:flex><span>    max_tool_iterations<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>,         <span style=color:#75715e># [可选] 防止工具死循环调用的最大次数</span>
</span></span><span style=display:flex><span>    model_client_stream<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>        <span style=color:#75715e># [可选] 是否开启流式输出</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h4 id=openaichatcompletionclient>OpenAIChatCompletionClient<a hidden class=anchor aria-hidden=true href=#openaichatcompletionclient>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>,                 <span style=color:#75715e># 模型名称</span>
</span></span><span style=display:flex><span>    api_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;...&#34;</span>,                  <span style=color:#75715e># 如果不设环境变量，可在此传入</span>
</span></span><span style=display:flex><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>,                <span style=color:#75715e># 创意程度 (0-1)</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=运行与调试命令>运行与调试命令<a hidden class=anchor aria-hidden=true href=#运行与调试命令>#</a></h3><ul><li><strong>运行代码</strong>： python your_script.py</li><li><strong>启动 AutoGen Studio (UI)</strong>：</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=display:flex><span>autogenstudio ui --port <span style=color:#ae81ff>8080</span> --appdir ./my-app
</span></span></code></pre></div><p>然后在浏览器访问 http://localhost:8080。</p><hr><h3 id=roundrobinteam>RoundRobinTeam<a hidden class=anchor aria-hidden=true href=#roundrobinteam>#</a></h3><p>你是一个由三个智能体组成的协作系统，专门用于回答 AI 编程相关的问题：</p><ol><li><strong>分析者 A</strong> 和 <strong>分析者 B</strong>：各自独立理解用户提出的问题，并分别提供一个清晰、可行、技术准确的回答。</li><li><strong>评审优化者 C</strong>：对比 A 与 B 的回答，选出质量更高的一方作为主答案；同时参考次优回答中的有效信息，对主答案进行查漏补缺、逻辑完善和语言优化；最终输出一个经过融合与提升的最终回答，并简要说明优化理由。</li></ol><p>请严格按照上述角色分工协作，确保最终回答准确、完整、实用，且优于任一初始回答。</p><p>【2025年11月版】完全小白也能一键部署到互联网的三专家协作系统（支持阿里通义千问 + DeepSeek）</p><p><strong>目标：</strong></p><ul><li>4～5个人同时访问（并发极低）</li><li>完全免费/超低成本部署（推荐 Railway / Fly.io / Render）</li><li>使用国产模型：写代码用 DeepSeek-Coder，专家思考用通义千问（Qwen-Max / Qwen-Plus）</li><li>代码带超级详细中文逐行注释 + 大白话解释</li></ul><p><strong>Autogen源码</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Python data-lang=Python><span style=display:flex><span><span style=color:#75715e># ================================== app.py 开始 ==================================</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> os                          <span style=color:#75715e># 用于读取系统环境变量（就是你设置的API密钥）</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> asyncio                     <span style=color:#75715e># AutoGen 0.4+ 全部都是异步的，必须导入</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastapi <span style=color:#f92672>import</span> FastAPI, Request   <span style=color:#75715e># FastAPI = 把AI变成网页的超级简单框架</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastapi.responses <span style=color:#f92672>import</span> HTMLResponse   <span style=color:#75715e># 返回HTML网页用的</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> fastapi.templating <span style=color:#f92672>import</span> Jinja2Templates <span style=color:#75715e># 用来渲染网页模板</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pydantic <span style=color:#f92672>import</span> BaseModel     <span style=color:#75715e># 用来定义用户发来的数据格式（就是问题）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- AutoGen 最新核心库（2025年11月版） -------------------</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent         <span style=color:#75715e># 智能体类</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.teams <span style=color:#f92672>import</span> RoundRobinTeam          <span style=color:#75715e># 团队类（轮流发言）</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.conditions <span style=color:#f92672>import</span> MaxMessageTermination  <span style=color:#75715e># 结束条件（最多说几句话）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 国产模型支持（阿里通义千问 + DeepSeek） -------------------</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.dashscope <span style=color:#f92672>import</span> DashScopeChatCompletionClient  <span style=color:#75715e># 通义千问</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.deepseek <span style=color:#f92672>import</span> DeepSeekChatCompletionClient    <span style=color:#75715e># DeepSeek</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 创建网页应用 -------------------</span>
</span></span><span style=display:flex><span>app <span style=color:#f92672>=</span> FastAPI(title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;我的AI三专家编程助手&#34;</span>)          <span style=color:#75715e># 整个网站的“大脑”</span>
</span></span><span style=display:flex><span>templates <span style=color:#f92672>=</span> Jinja2Templates(directory<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;templates&#34;</span>)   <span style=color:#75715e># 网页模板放在 templates 文件夹里</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 定义用户发来的数据格式 -------------------</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>QuestionRequest</span>(BaseModel):    <span style=color:#75715e># 用户发来的JSON长这样：{&#34;question&#34;: &#34;你的问题&#34;}</span>
</span></span><span style=display:flex><span>    question: str                    <span style=color:#75715e># 只有一个字段，就是问题本身</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 全局变量：只创建一次团队，省钱又快 -------------------</span>
</span></span><span style=display:flex><span>_expert_team <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>                  <span style=color:#75715e># 一开始是空的，第一次有人问问题时才创建</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 核心函数：创建三专家团队 -------------------</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>create_expert_team</span>():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 大白话：这里给每个专家装上不同的大脑</span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;正在创建三专家团队（只创建一次）...&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 从环境变量读取密钥（部署平台会自动帮你填）</span>
</span></span><span style=display:flex><span>    dashscope_key <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;DASHSCOPE_API_KEY&#34;</span>)   <span style=color:#75715e># 阿里通义千问的key</span>
</span></span><span style=display:flex><span>    deepseek_key <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;DEEPSEEK_API_KEY&#34;</span>)     <span style=color:#75715e># DeepSeek的key</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> dashscope_key:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;错误：没有设置 DASHSCOPE_API_KEY&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> deepseek_key:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;错误：没有设置 DEEPSEEK_API_KEY&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 专家1：代码专家 → 用DeepSeek（全球最强代码模型）</span>
</span></span><span style=display:flex><span>    coder <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;代码大师（DeepSeek）&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>DeepSeekChatCompletionClient(
</span></span><span style=display:flex><span>            model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;deepseek-coder&#34;</span>,      <span style=color:#75715e># 也可以改成 deepseek-coder-33b（更强）</span>
</span></span><span style=display:flex><span>            api_key<span style=color:#f92672>=</span>deepseek_key
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你只负责写出完美可运行的代码 + 超级详细的中文注释。用简体中文回答。&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 专家2：原理专家 → 用通义千问（理解力最强）</span>
</span></span><span style=display:flex><span>    analyst <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;原理大神（通义千问）&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>DashScopeChatCompletionClient(
</span></span><span style=display:flex><span>            model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;qwen-plus&#34;</span>,           <span style=color:#75715e># qwen-max 更强，但稍贵一点</span>
</span></span><span style=display:flex><span>            api_key<span style=color:#f92672>=</span>dashscope_key
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你负责用最容易懂的大白话讲解技术原理、设计思路、为什么这样写更好。&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 专家3：最终评审优化专家 → 也用通义千问</span>
</span></span><span style=display:flex><span>    reviewer <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;总编辑（通义千问）&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>DashScopeChatCompletionClient(
</span></span><span style=display:flex><span>            model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;qwen-plus&#34;</span>,
</span></span><span style=display:flex><span>            api_key<span style=color:#f92672>=</span>dashscope_key
</span></span><span style=display:flex><span>        ),
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        你是最终把关人，必须做到以下5点：
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        1. 对比前面两个专家的回答
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        2. 选出更好的作为主答案，并说明至少3个理由
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        3. 把另一个专家的亮点全部融合进来
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        4. 补充两人漏掉的关键点（尤其是新手最容易踩的坑）
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        5. 输出最终完美答案：完整代码 + 逐行注释 + 大白话解释 + 运行逻辑分析
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        用简体中文，语气超级友好！
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 把三个人拉进一个“轮流发言”的团队（A→B→C→A→B→C...）</span>
</span></span><span style=display:flex><span>    team <span style=color:#f92672>=</span> RoundRobinTeam(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;AI编程三剑客&#34;</span>,
</span></span><span style=display:flex><span>        agents<span style=color:#f92672>=</span>[coder, analyst, reviewer],   <span style=color:#75715e># 发言顺序：代码→原理→评审</span>
</span></span><span style=display:flex><span>        max_rounds<span style=color:#f92672>=</span><span style=color:#ae81ff>9</span>,                        <span style=color:#75715e># 最多9条消息（3轮完整讨论）</span>
</span></span><span style=display:flex><span>        termination_condition<span style=color:#f92672>=</span>MaxMessageTermination(<span style=color:#ae81ff>9</span>)  <span style=color:#75715e># 防止无限聊天</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> team
</span></span><span style=display:flex><span>    <span style=color:#75715e># 【大白话解释】：把刚才创建好的“三专家团队”这个对象“交出去”给调用者</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 【原理】：create_expert_team() 函数的最后一步就是 return team，</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#         这样外面调用 await create_expert_team() 就能拿到完整的团队对象</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#         以后所有提问都会用这个团队来讨论</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 获取团队（带缓存） -------------------</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_team</span>():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 定义一个异步函数，专门负责“拿到团队”</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 为什么叫“带缓存”？因为我们只想创建一次团队，后面重复用，省钱又快！</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>global</span> _expert_team
</span></span><span style=display:flex><span>    <span style=color:#75715e># global 关键字：告诉 Python “我要使用文件最上面定义的那个全局变量 _expert_team”</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># _expert_team 最开始是 None（空）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> _expert_team <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:               
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一次有人来问问题时，这里是 None，所以会走进这个 if</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 【大白话】：第一次访问网站的人触发了团队的“出生仪式”</span>
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        _expert_team <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> create_expert_team()
</span></span><span style=display:flex><span>        <span style=color:#75715e># await：因为 create_expert_team() 是异步函数，必须等它创建完团队才能继续</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 创建完后就把团队保存到全局变量 _expert_team 里，下次就不会再创建了</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 【原理】：这就是“懒加载 + 单例模式”，只创建一次，后面直接复用</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> _expert_team
</span></span><span style=display:flex><span>    <span style=color:#75715e># 无论第一次还是第100次，都把同一个团队对象返回给调用者</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这样所有用户共享同一个三专家团队，成本最低、速度最快！</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 网页首页 -------------------</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.get</span>(<span style=color:#e6db74>&#34;/&#34;</span>, response_class<span style=color:#f92672>=</span>HTMLResponse)
</span></span><span style=display:flex><span><span style=color:#75715e># @app.get(&#34;/&#34;) 是 FastAPI 的装饰器，意思是：</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 当有人在浏览器输入你的网站域名（比如 https://xxx.up.railway.app/）时，就执行下面的函数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># response_class=HTMLResponse：告诉 FastAPI 要返回一个完整的网页，而不是纯文字或JSON</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>home</span>(request: Request):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这个函数负责显示网站的首页</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># request: Request 是 FastAPI 自动传进来的，代表这次访问的所有信息（我们这里暂时用不到）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 把 templates/index.html 这个网页显示出来</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> templates<span style=color:#f92672>.</span>get_template(<span style=color:#e6db74>&#34;index.html&#34;</span>)<span style=color:#f92672>.</span>render({<span style=color:#e6db74>&#34;request&#34;</span>: request})
</span></span><span style=display:flex><span>    <span style=color:#75715e># 【大白话解释】：</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 1. templates.get_template(&#34;index.html&#34;) → 去 templates 文件夹里找到 index.html 这个网页文件</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 2. .render({&#34;request&#34;: request}) → 把一些数据塞进网页（这里只塞了一个 request，Jinja2模板需要）</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 3. 最后返回这个渲染好的完整网页给浏览器，用户就看到漂亮的输入框了！</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ------------------- 核心API：接收问题，返回答案 -------------------</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.post</span>(<span style=color:#e6db74>&#34;/ask&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># @app.post(&#34;/ask&#34;) 表示：当前端用 POST 方法发请求到 /ask 这个地址时，执行下面的函数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 前端的 JavaScript 代码里 fetch(&#39;/ask&#39;, ...) 就是调用这里！</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>ask_question</span>(req: QuestionRequest):
</span></span><span style=display:flex><span>    <span style=color:#75715e># req 就是用户发来的数据，格式是 {&#34;question&#34;: &#34;用户的问题&#34;}</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># QuestionRequest 是我们前面用 pydantic 定义的模型，会自动检查数据格式</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    question <span style=color:#f92672>=</span> req<span style=color:#f92672>.</span>question<span style=color:#f92672>.</span>strip()
</span></span><span style=display:flex><span>    <span style=color:#75715e># .strip() 把用户输入前后的空格、换行都去掉，防止空问题</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> question:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 如果用户只点了按钮但啥也没写，就返回一个友好的错误</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;error&#34;</span>: <span style=color:#e6db74>&#34;问题不能为空哦~&#34;</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:  
</span></span><span style=display:flex><span>        <span style=color:#75715e># 开始真正干活！下面所有代码都包在 try 里，出错就不会崩溃</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        team <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> get_team()            
</span></span><span style=display:flex><span>        <span style=color:#75715e># 先拿到我们已经准备好的三专家团队（如果还没创建，就会自动创建）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;收到问题：</span><span style=color:#e6db74>{</span>question<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 在服务器后台打印一下，便于你看日志，知道有人来问问题了</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 真正开始三专家讨论！这是整个程序的核心！</span>
</span></span><span style=display:flex><span>        result <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> team<span style=color:#f92672>.</span>run(task<span style=color:#f92672>=</span>question)
</span></span><span style=display:flex><span>        <span style=color:#75715e># team.run() 是 AutoGen 0.4+ 的官方方法</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 它会让三个专家轮流发言9轮，最终得出一个完美答案</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># await 必须加，因为这是异步操作，要等他们讨论完</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 返回最终完美答案给前端网页</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;question&#34;</span>: question,              <span style=color:#75715e># 把问题原样返回，方便前端显示</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;answer&#34;</span>: result<span style=color:#f92672>.</span>final_output,     <span style=color:#75715e># 这就是三专家最终商量出来的超级详细答案！</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;status&#34;</span>: <span style=color:#e6db74>&#34;success&#34;</span>                <span style=color:#75715e># 告诉前端“成功了”</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 如果中间任何地方出错了（比如网络问题、API余额不足），都会走到这里</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;出错了：</span><span style=color:#e6db74>{</span>e<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)                   <span style=color:#75715e># 在后台打印真实错误，方便你调试</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {<span style=color:#e6db74>&#34;error&#34;</span>: <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;系统出错：</span><span style=color:#e6db74>{</span>str(e)<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>} <span style=color:#75715e># 给用户一个友好的提示，同时把真实错误也显示（上线后可以隐藏）</span>
</span></span></code></pre></div><p><strong>2、网页文件（超级简单）</strong></p><p>新建文件夹 templates，里面新建 index.html，复制下面全部内容：</p><pre tabindex=0><code>&lt;!-- templates/index.html --&gt;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;meta charset=&#34;utf-8&#34;&gt; &lt;!-- 告诉浏览器用UTF-8编码，防止中文乱码 --&gt;
    &lt;title&gt;AI三专家编程助手&lt;/title&gt; &lt;!-- 浏览器标签页显示的标题 --&gt;
    &lt;style&gt;
        /* ==================== 美化样式（可以完全不用管） ==================== */
        body { 
            font-family: &#34;Microsoft YaHei&#34;, Arial; 
            background: linear-gradient(to bottom, #667eea, #764ba2); /* 渐变背景 */
            min-height: 100vh; 
            margin:0; 
            display:flex; 
            align-items:center; 
            justify-content:center;
        }
        .box { 
            width: 90%; 
            max-width: 900px; 
            background: white; 
            border-radius: 20px; 
            padding: 40px; 
            box-shadow: 0 20px 40px rgba(0,0,0,0.2); 
        }
        textarea { 
            width: 100%; 
            height: 120px; 
            padding: 15px; 
            font-size: 18px; 
            border: 2px solid #ddd; 
            border-radius: 12px; 
        }
        button { 
            margin-top: 20px; 
            padding: 15px 40px; 
            font-size: 20px; 
            background: #667eea; 
            color: white; 
            border: none; 
            border-radius: 12px; 
            cursor: pointer; 
        }
        button:hover { background: #5a6fd8; }
        #result { 
            margin-top: 30px; 
            padding: 25px; 
            border: 1px solid #eee; 
            border-radius: 12px; 
            background: #f8f9fa; 
            line-height: 1.8; 
            font-size: 17px; 
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div class=&#34;box&#34;&gt;
    &lt;h1 style=&#34;text-align:center; color:#667eea;&#34;&gt;🚀 AI三专家编程助手&lt;/h1&gt;
    &lt;p style=&#34;text-align:center; color:#555;&#34;&gt;
        问任何编程问题，三位大佬会给你最完美的答案！（代码+详细解释）
    &lt;/p&gt;
    
    &lt;!-- 用户输入问题的文本框 --&gt;
    &lt;textarea id=&#34;question&#34; placeholder=&#34;例如：用Python写一个自动发微信消息的脚本&#34;&gt;&lt;/textarea&gt;
    
    &lt;div style=&#34;text-align:center;&#34;&gt;
        &lt;button onclick=&#34;ask()&#34;&gt;立即提问&lt;/button&gt; &lt;!-- 点击按钮就触发 ask() 函数 --&gt;
    &lt;/div&gt;
    
    &lt;!-- 答案会显示在这里 --&gt;
    &lt;div id=&#34;result&#34;&gt;答案会在这里显示～&lt;/div&gt;
&lt;/div&gt;

&lt;!-- ==================== 下面是核心 JavaScript 代码，每一行都有详细注释 ==================== --&gt;
&lt;script&gt;
async function ask() {
    // 【大白话】：这个函数就是“点击按钮后”要干的事
    
    // 1. 先拿到用户在文本框里输入的内容
    const q = document.getElementById(&#39;question&#39;).value.trim();
    // document.getElementById(&#39;question&#39;) → 找到 id 为 question 的 textarea
    // .value → 取出用户输入的文字
    // .trim() → 把开头结尾的空格、回车都去掉，防止空提交

    // 2. 如果用户啥也没写，就弹窗提醒
    if (!q) {
        return alert(&#34;请先输入问题哦~&#34;);
        // return 表示函数到这里就结束，不再往下执行
    }
    
    // 3. 把“答案区”先改成“思考中”，让用户知道正在处理
    document.getElementById(&#39;result&#39;).innerHTML = 
        &#34;🤖 三位专家正在激烈讨论中，请耐心等待30-60秒...&#34;;
    // innerHTML = 直接替换 div 里面的所有内容

    // 4. 真正向后端发送问题（核心！）
    // fetch 是浏览器内置的“发网络请求”神器
    const res = await fetch(&#39;/ask&#39;, {
        // &#39;/ask&#39; 就是我们 FastAPI 里定义的 @app.post(&#34;/ask&#34;) 接口
        method: &#39;POST&#39;,                                      // 用 POST 方式发送（比 GET 安全）
        headers: {&#39;Content-Type&#39;: &#39;application/json&#39;},       // 告诉服务器“我发的是 JSON 数据”
        body: JSON.stringify({question: q})                  // 把问题包装成 {&#34;question&#34;: &#34;用户的问题&#34;}
        // JSON.stringify 把对象转成字符串，这是标准格式
    });
    // await：必须等服务器回应后才能继续（异步，等同于 Python 的 await）

    // 5. 把服务器返回的 JSON 数据取出来
    const data = await res.json();
    // res.json() 会把返回的 JSON 字符串解析成 JavaScript 对象

    // 6. 判断服务器是成功还是出错了
    if (data.error) {
        // 如果后端返回了 error 字段，说明出问题了
        document.getElementById(&#39;result&#39;).innerHTML = 
            &#34;&lt;span style=&#39;color:red;&#39;&gt;出错了：&#34; + data.error + &#34;&lt;/span&gt;&#34;;
    } else {
        // 成功！把问题和最终答案漂亮地显示出来
        document.getElementById(&#39;result&#39;).innerHTML = 
            &#34;&lt;h3&gt;📌 你的问题：&lt;/h3&gt;&#34; + data.question + 
            &#34;&lt;h3 style=&#39;color:#667eea;&#39;&gt;✅ 最终答案：&lt;/h3&gt;&#34; + 
            data.answer.replace(/\n/g, &#34;&lt;br&gt;&#34;);  
        // data.answer.replace(/\n/g, &#34;&lt;br&gt;&#34;) 的作用：
        // 把答案里的换行符 \n 全部换成 HTML 的 &lt;br&gt;，这样网页才能正确换行显示
    }
}
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><p><strong>3.详细的 GitHub + Railway 一键部署教程（手把手截图级）</strong></p><p><strong>步骤1：创建 GitHub 仓库（1分钟）</strong></p><ol><li>打开 <a href=https://github.com/new>https://github.com/new</a></li><li>Repository name 填：ai-expert-assistant（随便填）</li><li>点 Create repository</li></ol><p><strong>步骤2：把代码上传到 GitHub（3分钟）</strong></p><ol><li>把上面两个文件保存到电脑一个文件夹里：</li></ol><pre tabindex=0><code>ai-expert-assistant/
├── app.py
└── templates/
    └── index.html
</code></pre><p>2.打开终端（Mac）或命令提示符（Windows），进入这个文件夹，运行：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git init
</span></span><span style=display:flex><span>git add .
</span></span><span style=display:flex><span>git commit -m <span style=color:#e6db74>&#34;first commit&#34;</span>
</span></span><span style=display:flex><span>git branch -M main
</span></span><span style=display:flex><span>git remote add origin https://github.com/你的用户名/ai-expert-assistant.git
</span></span><span style=display:flex><span>git push -u origin main
</span></span></code></pre></div><p>（第一次会让你登录GitHub）</p><p><strong>步骤3：申请两个免费API密钥（5分钟）</strong></p><ol><li>阿里通义千问：https://help.aliyun.com/zh/dashscope/developer-reference/tongyi-qwen-quick-start → 控制台 → API-KEY → 复制</li><li>DeepSeek：https://platform.deepseek.com/api-keys → 注册 → 直接复制 key</li></ol><p><strong>步骤4：Railway 一键部署（最简单！3分钟）</strong></p><ol><li>打开 <a href=https://railway.app>https://railway.app</a> → 用 GitHub 登录</li><li>点右上角 “New Project”</li><li>选 “Deploy from GitHub”</li><li>选你刚创建的仓库 ai-expert-assistant</li><li>Railway 自动检测到是 Python 项目，会让你确认 → 直接点 Deploy</li><li>部署完成后，点你的项目 → Variables 标签 → 加三行</li></ol><pre tabindex=0><code>DASHSCOPE_API_KEY    填你的通义千问key
DEEPSEEK_API_KEY     填你的DeepSeek key
PORT                 8000
</code></pre><p>​ 7.保存 → 等待30秒重新部署 → 点右上角的网址（类似 <a href=https://ai-expert-assistant.up.railway.app>https://ai-expert-assistant.up.railway.app</a>）</p><p>大功告成！把这个网址发给你的4-5个朋友，他们就能无限使用了！</p><p>本地先测试一下（可选）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install fastapi uvicorn <span style=color:#e6db74>&#34;autogen-agentchat&#34;</span> <span style=color:#e6db74>&#34;autogen-ext[dashscope,deepseek]&#34;</span>
</span></span><span style=display:flex><span>uvicorn app:app --reload
</span></span></code></pre></div><p>现在你拥有了一个比 ChatGPT 还强的、完全属于自己的国产AI编程助手网站！🎉</p><h2 id=autogen组件代码解释指南>AutoGen组件代码解释指南<a hidden class=anchor aria-hidden=true href=#autogen组件代码解释指南>#</a></h2><ul><li><strong>GraphFlow</strong>：这是一个用于结构化多代理工作流的工具，似乎可以可靠地控制代理执行顺序，但需注意实验性，可能有API变更。</li><li><strong>Magentic-One</strong>：一个通用多代理系统，证据显示它擅长复杂任务协作，但随机性可能导致不一致结果。</li><li><strong>Swarm</strong>：OpenAI的轻量框架，用于代理协调，看起来易用但实验性质强，适合原型测试。</li><li><strong>McpWorkbench</strong>：AutoGen的工具集成平台，帮助代理访问外部服务，安全风险需警惕。</li></ul><p>这些组件的代码示例基于最新文档，通常涉及Python异步编程和代理实例化。逐行解释包括语法（技术细节）和大白话（简单原理）。每个组件的代码放在单独“文件”中展示。</p><p>AutoGen框架是一个开源的多代理AI开发工具，由微软xAI团队维护，用于构建协作AI系统。下面这份调研笔记详细解释了您查询的代码示例与逐行解析，重点针对GraphFlow、Magentic-One、Swarm和McpWorkbench。笔记基于2025年最新文档和教程，整合了语法角度（技术细节，如变量赋值、函数调用）和大白话原理（简单比喻，如“像团队分工”）两种方式解释。每个组件的代码放在一个虚拟“文件”中（以代码块模拟），方便复制展示。笔记还包括组件定义、解决问题、运行原理、痛点、益处和案例。</p><h3 id=1-graphflow-图流事件驱动工作流>1. GraphFlow (图流/事件驱动工作流)<a hidden class=anchor aria-hidden=true href=#1-graphflow-图流事件驱动工作流>#</a></h3><blockquote><p><strong>注意</strong>：在 AutoGen v0.4 中，没有一个类直接叫 GraphFlow，这个词通常指代<strong>基于图（Graph）的事件驱动工作流</strong>。这是 v0.4 的核心架构理念。</p></blockquote><ul><li><p><strong>GraphFlow</strong> 是 AutoGen 0.4+（尤其是 AgentChat API）中一个<strong>实验性</strong>的 multi-agent workflow 工具（目前还在快速迭代，API 可能会变）。它把多个 agent 当成图（graph）的节点，用有向边（edges）来精确控制它们之间的执行顺序和消息流动。</p><p><strong>解决了什么问题？</strong> 以前 AutoGen 的 GroupChat（比如 RoundRobin、Selector）是“自由聊天”模式，agent 轮流发言，流程不固定，容易出现：</p><ul><li>对话乱序、重复</li><li>无法保证某些步骤一定先执行（比如必须先研究 → 再写代码 → 再审查）</li><li>难以做条件分支、循环、并行（fan-out/fan-in）</li></ul><p>GraphFlow 把 workflow 变成<strong>可编程的图</strong>，开发者可以明确说“这个 agent 完成后，下一步走哪个（或哪几个）”，让多 agent 协作变得<strong>确定性、可视化、可调试</strong>。</p><p><strong>运行原理</strong></p><ul><li>用 DiGraphBuilder 构建一个有向图（Directed Graph）</li><li>每个节点 = 一个 agent</li><li>每条边 = “从 A 到 B 的消息流动”，可以加条件（condition=lambda msg: &mldr;）</li><li>执行时从入口节点（entry point / source nodes）开始，按图拓扑顺序自动推进，支持循环、条件分支、并发（多个 outgoing edges 时可以同时执行）</li></ul><p><strong>痛点解决 & 带来的启示</strong></p><ul><li>痛点：聊天式多 agent 太“随机”，企业级任务需要严格流程控制</li><li>启示：把多 agent 当成“工作流引擎”而不是“群聊”，更适合生产环境（如审批流、研究→写作→审查）</li></ul><p><strong>怎么用？一个简单案例（fan-out → fan-in）</strong> 任务：让一个 agent 生成一段文字，然后同时翻译成中文和日文，最后汇总。</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 先导入异步运行必须的 asyncio</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 从 AutoGen 导入我们需要的几个核心类</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent          <span style=color:#75715e># 基础的助手 Agent</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.teams <span style=color:#f92672>import</span> DiGraphBuilder, GraphFlow  <span style=color:#75715e># 图构建器和图流程</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console                     <span style=color:#75715e># 用来在终端实时打印对话</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient  <span style=color:#75715e># OpenAI 模型客户端</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义一个 async 主函数（AutoGen 0.4 全部用异步）</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>() <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第1步：创建一个连接 OpenAI 的客户端（这里用 gpt-4o）</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 你需要提前在环境变量里设置 export OPENAI_API_KEY=sk-...</span>
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 等价于以前的 OpenAIWrapper，只不过现在叫这个名字</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第2步：创建 4 个不同的助手 Agent（每个都用同一个模型）</span>
</span></span><span style=display:flex><span>    generator <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;generator&#34;</span>,                  <span style=color:#75715e># Agent 的名字，后面图里会用到</span>
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,               <span style=color:#75715e># 用上面创建的 OpenAI 客户端</span>
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是一个内容生成专家，请根据用户任务生成一段英文段落。&#34;</span>  <span style=color:#75715e># 系统提示词，决定 Agent 的角色</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    translator_zh <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;translator_zh&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你只负责把英文翻译成简体中文，不要加额外解释。&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    translator_ja <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;translator_ja&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你只负责把英文翻译成日文，不要加额外解释。&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    summarizer <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;summarizer&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;把所有翻译结果汇总，用中文输出最终版本。&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第3步：开始构建一张“流程图”</span>
</span></span><span style=display:flex><span>    builder <span style=color:#f92672>=</span> DiGraphBuilder()             <span style=color:#75715e># 创建一个空的图构建器</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 把上面 4 个 Agent 都加入图里（变成图的节点）</span>
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_node(generator)
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_node(translator_zh)
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_node(translator_ja)
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_node(summarizer)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第4步：画箭头——决定执行顺序（边）</span>
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_edge(generator, translator_zh)   <span style=color:#75715e># generator 完成后 → 发消息给中文翻译</span>
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_edge(generator, translator_ja)   <span style=color:#75715e># generator 完成后 → 同时发消息给日文翻译（并行！）</span>
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_edge(translator_zh, summarizer)  <span style=color:#75715e># 中文翻译完成后 → 发给汇总 Agent</span>
</span></span><span style=display:flex><span>    builder<span style=color:#f92672>.</span>add_edge(translator_ja, summarizer)  <span style=color:#75715e># 日文翻译完成后 → 发给汇总 Agent</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第5步：把图和所有 Agent 打包成一个可以运行的“团队”</span>
</span></span><span style=display:flex><span>    flow <span style=color:#f92672>=</span> GraphFlow(
</span></span><span style=display:flex><span>        participants<span style=color:#f92672>=</span>builder<span style=color:#f92672>.</span>get_participants(),   <span style=color:#75715e># 所有参与的 Agent</span>
</span></span><span style=display:flex><span>        graph<span style=color:#f92672>=</span>builder<span style=color:#f92672>.</span>build()                      <span style=color:#75715e># 刚才画好的图</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第6步：真正开始运行！任务从入度为 0 的节点（这里是 generator）开始</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> Console(flow<span style=color:#f92672>.</span>run_stream(
</span></span><span style=display:flex><span>        task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;写一段介绍北京故宫的英文段落（大约100字）&#34;</span>
</span></span><span style=display:flex><span>    ))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动程序</span>
</span></span><span style=display:flex><span>asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><hr><h3 id=2-magentic-one-磁性一号--全能团队>2. Magentic-One (磁性一号 / 全能团队)<a hidden class=anchor aria-hidden=true href=#2-magentic-one-磁性一号--全能团队>#</a></h3><ul><li><strong>是什么</strong>：
它不是一个功能，而是微软官方基于 AutoGen 打造的一个<strong>通用的、高性能的多智能体系统（System）</strong>。
<strong>大白话</strong>：它是一个<strong>现成的“复仇者联盟”</strong>。你不需要自己去写“程序员Agent”、“搜索Agent”，微软已经帮你写好了一组最强的 Agent 搭配，里面有一个类似“神盾局局长”的 Orchestrator 在指挥。</li><li><strong>解决了什么问题</strong>：<ul><li><strong>通用性</strong>：以前你写 Agent 只能干一件事。Magentic-One 号称可以解决各种复杂任务（上网查资料 + 写代码 + 操作文件）。</li><li><strong>自我修正</strong>：如果代码跑不通，它内部会自动循环修复，直到成功。</li></ul></li><li><strong>痛点与原理& 启示</strong>：<ul><li><em>痛点</em>：新手自己组装的 Agent 团队往往很笨，容易陷入死循环。</li><li><em>原理</em>：采用 Orchestrator（指挥官）+ Specialists（专家组：WebSurfer, Coder, Executor）的架构。</li><li>启示：把不同技能拆成独立 agent + 一个聪明指挥官，是解决“通用复杂任务”的有效模式</li><li>4 个专业 agent：<ul><li>WebSurfer：多模态网页浏览（看图、点击、填写表单）</li><li>FileSurfer：本地文件系统读写</li><li>Coder：写代码</li><li>Executor（Computer Terminal）：执行代码、安装库</li></ul></li></ul></li><li><strong>源码示例与逐行解析</strong>：
<em>(注意：Magentic-One 通常作为独立包 autogen-magentic-one 存在，以下演示其核心使用逻辑)</em></li></ul><pre tabindex=0><code>import asyncio
from autogen_ext.models.openai import OpenAIChatCompletionClient
# 假设安装了 magentic-one 扩展包
from autogen_magentic_one.agents import MagenticOneOrchestrator, MagenticOneCoder

async def main():
    client = OpenAIChatCompletionClient(model=&#34;gpt-4o&#34;)

    # [1. 这里的核心是 Orchestrator (总指挥)]
    # Magentic-One 的厉害之处在于这个预设好的指挥官，它内置了非常复杂的策略
    # 它知道什么时候该叫程序员，什么时候该叫浏览器
    team_leader = MagenticOneOrchestrator(
        name=&#34;MagenticManager&#34;,
        model_client=client
    )
    
    # [2. 这是一个全能的运行入口]
    # 你不需要手动把 Agent 连起来，Magentic-One 封装好了
    # 这行代码背后，可能有4-5个 Agent 在疯狂交互：上网查股价 -&gt; 写绘图代码 -&gt; 运行 -&gt; 存图
    await team_leader.run_task(
        &#34;请上网查询微软过去一年的股价，并用 Python 画一张折线图保存为 stock.png&#34;
    )

if __name__ == &#34;__main__&#34;:
    asyncio.run(main())
</code></pre><p><strong>Magentic-One（开箱即用最强多智能体团队）—— 最详细注释版</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.teams.magentic_one <span style=color:#f92672>import</span> MagenticOne  <span style=color:#75715e># 直接导入现成的团队</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)  <span style=color:#75715e># 可以换其他模型</span>
</span></span><span style=display:flex><span>    m1 <span style=color:#f92672>=</span> MagenticOne(client<span style=color:#f92672>=</span>client)                     <span style=color:#75715e># 一行创建一个完整 5-agent 团队</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> Console(m1<span style=color:#f92672>.</span>run_stream(task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;帮我查找最近 3 篇关于量子计算的 arXiv 论文，并用中文总结每篇的核心贡献&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><p><strong>逐行解释</strong>：</p><ul><li>MagenticOne(client=client)：内部自动创建 Orchestrator + 4 个专业 agent，已经配好工具（Playwright 浏览、Docker 代码执行等）</li><li>m1.run_stream(task=&mldr;)：直接扔一个复杂任务，它会自动规划、浏览网页、下载 PDF、总结……</li></ul><p>这就是“开箱即用”的通用 agent 系统，几乎不需要你写任何 agent 定义。</p><hr><h3 id=3-swarm-蜂群模式--动态交接>3. Swarm (蜂群模式 / 动态交接)<a hidden class=anchor aria-hidden=true href=#3-swarm-蜂群模式--动态交接>#</a></h3><ul><li><p><strong>是什么</strong>：
这是 OpenAI 提出的一种轻量级多 Agent 模式，AutoGen v0.4 完美支持。它的核心概念是 <strong>Handoffs（交接）</strong>。
<strong>大白话</strong>：就像打电话给客服。</p><ul><li>你：“我要退款。”</li><li>客服A：“这事我管不了，但我知道‘退款专员B’能管，**转接（Handoff）**给B。”</li><li>Agent 自己决定下一棒交给谁，而不是由一个总管来分配。</li></ul><p><strong>运行原理</strong></p><ul><li>每个 agent 有 handoffs=[&ldquo;agent_name&rdquo;, &mldr;] 列表，告诉它可以把任务交给谁</li><li>agent 用特殊工具 handoff_to_xxx 把控制权完全交给下一个 agent（上下文共享）</li><li>整个团队像“接力赛”而不是“群聊</li></ul></li><li><p><strong>解决了什么问题</strong>：</p><ul><li><strong>去中心化</strong>：不需要一个超级聪明的“大总管”来分配任务，Agent 自己就能根据对话上下文把锅甩给对的人。</li><li><strong>灵活性</strong>：流程非常自然，像人类聊天一样流转。</li></ul></li><li><p><strong>痛点与原理& 启示</strong>：</p><ul><li><em>痛点</em>：传统的 GroupChat 有时候很乱，所有人都在一个群里抢着说话。</li><li><em>原理</em>：每个 Agent 的工具箱里都有一个“转接工具”，返回 Handoff 对象。</li><li>启示：把多 agent 当成“服务路由”，非常适合对话式应用（客服、订票）</li></ul></li><li><p><strong>源码示例与逐行解析</strong>：</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.messages <span style=color:#f92672>import</span> Handoff
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.teams <span style=color:#f92672>import</span> Swarm
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># [1. 定义“接待员” Agent]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 注意 handoffs 参数：允许它把任务转交给 flight_agent</span>
</span></span><span style=display:flex><span>    receptionist <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;receptionist&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是前台。如果用户问航班，转交给 flight_agent。&#34;</span>,
</span></span><span style=display:flex><span>        handoffs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;flight_agent&#34;</span>]  <span style=color:#75715e># 核心：给它一个通讯录，告诉它能转给谁</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># [2. 定义“航班专员” Agent]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 它的 handoffs 指向 receptionist，意味着处理完可以转回去，或者结束</span>
</span></span><span style=display:flex><span>    flight_agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;flight_agent&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是航班专员，负责查询机票。&#34;</span>,
</span></span><span style=display:flex><span>        handoffs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;receptionist&#34;</span>]
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># [3. 组建 Swarm (蜂群) 团队]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Swarm 模式不需要路由器，Agent 自己决定下一个是谁</span>
</span></span><span style=display:flex><span>    team <span style=color:#f92672>=</span> Swarm([receptionist, flight_agent], model_client<span style=color:#f92672>=</span>client)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># [4. 运行]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 用户问：查机票 -&gt; 前台(接单) -&gt; 前台(无能力) -&gt; 触发Handoff -&gt; 航班专员(接单) -&gt; 回答</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> team<span style=color:#f92672>.</span>run(task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;我想查一张去北京的机票&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><hr><p>这四个概念是 AutoGen v0.4 生态中非常核心、但也容易混淆的术语。它们分别代表了：<strong>工作流架构、超级智能体团队、交互模式、工具标准</strong>。</p><p>为了让你直观理解，我将采用**“概念解析 + 源码与逐行注释合并”**的方式来展示。</p><hr><p><strong>Swarm（接力式多智能体，类似客服路由）—— 最详细注释版</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent        <span style=color:#75715e># 基础 Agent</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.teams <span style=color:#f92672>import</span> Swarm                  <span style=color:#75715e># Swarm 团队类</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第1个 Agent：只负责查航班，查完必须把对话交给下一个</span>
</span></span><span style=display:flex><span>    search_agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;flight_search&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你只负责查询航班信息，绝对不要自己订票。查完后必须使用 handoff 把对话交给 booking_agent。&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e># 关键：handoffs 列表里写明它可以把任务交给谁</span>
</span></span><span style=display:flex><span>        handoffs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;booking_agent&#34;</span>, <span style=color:#e6db74>&#34;user&#34;</span>]   <span style=color:#75715e># 可以交给订票员或直接交给用户</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第2个 Agent：只负责订票和改签</span>
</span></span><span style=display:flex><span>    booking_agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>        name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;booking&#34;</span>,
</span></span><span style=display:flex><span>        model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>        system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你只负责订票、改签、退票等操作。完成后必须 handoff 给 user。&#34;</span>,
</span></span><span style=display:flex><span>        handoffs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;user&#34;</span>]   <span style=color:#75715e># 只能交给用户，不能再交给别人</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 创建 Swarm 团队，第一个 Agent 会自动成为入口</span>
</span></span><span style=display:flex><span>    team <span style=color:#f92672>=</span> Swarm(participants<span style=color:#f92672>=</span>[search_agent, booking_agent])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 开始对话——用户说想查航班</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> Console(team<span style=color:#f92672>.</span>run_stream(
</span></span><span style=display:flex><span>        task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;帮我查一下明天从北京到上海的航班，有什么便宜的？&#34;</span>
</span></span><span style=display:flex><span>    ))
</span></span><span style=display:flex><span>    <span style=color:#75715e># 你会看到：</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 1. search_agent 先回答航班信息</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 2. 自动 handoff（交接）给 booking_agent</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 3. booking_agent 问你要不要订票</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 4. 最后交还给用户</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><p>运行后你会看到：search_agent 查完航班 → 自动 handoff 到 booking_agent → booking_agent 问你要不要订 → 最后 handoff 回 user。</p><hr><h3 id=4-mcpworkbench-mcp-工作台--通用工具接口>4. McpWorkbench (MCP 工作台 / 通用工具接口)<a hidden class=anchor aria-hidden=true href=#4-mcpworkbench-mcp-工作台--通用工具接口>#</a></h3><ul><li><p><strong>是什么</strong>：
McpWorkbench 是 AutoGen 提供的 Model Context Protocol (MCP) 客户端工具。MCP 是 Anthropic 发起的一个开放协议，让 LLM 能安全地调用外部工具服务器（比如 Playwright 浏览网页、文件系统、Git 等）。
<strong>大白话</strong>：以前你想让 AI 连 GitHub、连 Google Drive、连本地文件，你得给每个平台写一套 Python 代码。现在有了 MCP，就像 <strong>USB 接口</strong>。GitHub 提供了一个“USB设备”（MCP Server），AutoGen 提供了一个“USB插座”（McpWorkbench），插上就能用，不用写驱动代码。</p></li><li><p><strong>解决了什么问题</strong>：</p><ul><li><strong>工具荒</strong>：开发者不用自己苦哈哈地写工具函数了，直接用社区现成的 MCP Server。</li><li><strong>安全性</strong>：MCP Server 运行在独立进程里，不会搞坏你的主程序。</li></ul><p><strong>运行原理</strong></p><ul><li>启动一个 MCP server（比如 @playwright/mcp 浏览网页）</li><li>用 McpWorkbench 连接这个 server</li><li>把 workbench 传给 AssistantAgent，agent 就能像调用普通工具一样调用 MCP 工具</li></ul></li><li><p><strong>痛点与原理& 启示</strong>：</p><ul><li><em>痛点</em>：连接外部世界（World Grounding）太难了，每个 API 文档都不一样。</li><li><em>原理</em>：通过标准化的协议（JSON-RPC over Stdio/SSE）与外部工具进程通信。</li><li>启示：把工具外部化成服务，是未来 agent 生态的方向（类似 Claude Desktop</li></ul></li><li><p><strong>源码示例与逐行解析</strong>：</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.tools.mcp <span style=color:#f92672>import</span> McpWorkbench, StdioServerParams
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># [1. 配置 MCP 服务器参数]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 这是一个独立的进程。假设我们安装了一个叫 &#39;fetch-mcp&#39; 的工具，能抓取网页</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 相当于我们买了一个“USB设备”</span>
</span></span><span style=display:flex><span>    server_params <span style=color:#f92672>=</span> StdioServerParams(
</span></span><span style=display:flex><span>        command<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;uvx&#34;</span>, <span style=color:#75715e># 使用 uvx 运行命令 (Python包管理工具)</span>
</span></span><span style=display:flex><span>        args<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;mcp-server-fetch&#34;</span>] <span style=color:#75715e># 具体的 MCP Server 包名</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># [2. 启动工作台 (McpWorkbench)]</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># async with 相当于把插头插上，通电</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>with</span> McpWorkbench(server_params) <span style=color:#66d9ef>as</span> workbench:
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># [3. 创建 Agent 并把 workbench 给他]</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 我们不需要定义 tool 列表，workbench 会自动读取 MCP Server 里有什么工具</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 并自动喂给 Agent</span>
</span></span><span style=display:flex><span>        agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;web_surfer&#34;</span>,
</span></span><span style=display:flex><span>            model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>            tools<span style=color:#f92672>=</span>[workbench], <span style=color:#75715e># 直接把整个工具台给它</span>
</span></span><span style=display:flex><span>            system_message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你可以使用工具来抓取网页内容。&#34;</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># [4. 运行]</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Agent 会自动发现 workbench 里有个 &#39;fetch&#39; 工具，并调用它</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> Console(agent<span style=color:#f92672>.</span>run_stream(task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;抓取 https://example.com 的内容并总结&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><p><strong>McpWorkbench（网页浏览神器，基于 MCP 协议）</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> asyncio
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 核心组件导入</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.agents <span style=color:#f92672>import</span> AssistantAgent
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_agentchat.ui <span style=color:#f92672>import</span> Console
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.models.openai <span style=color:#f92672>import</span> OpenAIChatCompletionClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># MCP 相关（Model Context Protocol）</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> autogen_ext.tools.mcp <span style=color:#f92672>import</span> McpWorkbench, StdioServerParams   <span style=color:#75715e># MCP 客户端和工作台</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>() <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第1步：定义怎么启动 Playwright MCP 服务器（只需要全局安装一次）</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 你需要在终端先执行一次：npm install -g @playwright/mcp@latest</span>
</span></span><span style=display:flex><span>    server_params <span style=color:#f92672>=</span> StdioServerParams(
</span></span><span style=display:flex><span>        command<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;npx&#34;</span>,                                          <span style=color:#75715e># 用 npx 启动</span>
</span></span><span style=display:flex><span>        args<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;@playwright/mcp@latest&#34;</span>, <span style=color:#e6db74>&#34;--headless&#34;</span>],          <span style=color:#75715e># 参数：最新版 + 无头模式</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 第2步：用 async with 自动启动和关闭 MCP 服务器（用完自动杀进程）</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>with</span> McpWorkbench(server_params) <span style=color:#66d9ef>as</span> mcp:   <span style=color:#75715e># mcp 就是一堆网页工具的集合</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 创建 OpenAI 客户端</span>
</span></span><span style=display:flex><span>        client <span style=color:#f92672>=</span> OpenAIChatCompletionClient(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 创建一个会浏览网页的 Agent</span>
</span></span><span style=display:flex><span>        agent <span style=color:#f92672>=</span> AssistantAgent(
</span></span><span style=display:flex><span>            name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;web_surfer&#34;</span>,
</span></span><span style=display:flex><span>            model_client<span style=color:#f92672>=</span>client,
</span></span><span style=display:flex><span>            workbench<span style=color:#f92672>=</span>mcp,                  <span style=color:#75715e># 重点！把 MCP 工具注入给 Agent</span>
</span></span><span style=display:flex><span>            max_tool_iterations<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>,         <span style=color:#75715e># 最多允许调用 20 次工具（防止死循环）</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第3步：让它去干活——打开 GitHub 页面并读取 star 数</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> Console(agent<span style=color:#f92672>.</span>run_stream(
</span></span><span style=display:flex><span>            task<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;打开 https://github.com/microsoft/autogen ，告诉我这个仓库当前有多少个 star？&#34;</span>
</span></span><span style=display:flex><span>        ))
</span></span><span style=display:flex><span>        <span style=color:#75715e># Agent 会：</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. 调用 MCP 的 open_url 工具打开页面</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. 调用 screenshot 或 get_element 工具找 star 按钮</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 3. 提取数字并返回给你</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 启动程序</span>
</span></span><span style=display:flex><span>asyncio<span style=color:#f92672>.</span>run(main())
</span></span></code></pre></div><hr><h3 id=总结它们给开发者带来了什么>总结：它们给开发者带来了什么？<a hidden class=anchor aria-hidden=true href=#总结它们给开发者带来了什么>#</a></h3><table><thead><tr><th>功能</th><th>关键词</th><th>给开发者带来了什么？</th><th>适合场景</th></tr></thead><tbody><tr><td><strong>GraphFlow</strong></td><td><strong>流程图</strong></td><td>像画流程图一样写代码，逻辑极其清晰，不再是一团乱麻。</td><td>复杂的业务审批流、条件分支任务。</td></tr><tr><td><strong>Magentic-One</strong></td><td><strong>全能团队</strong></td><td>开箱即用的“超级员工”，不用自己设计团队结构，直接解决难题。</td><td>复杂通用任务（如“做个市场调研PPT”）。</td></tr><tr><td><strong>Swarm</strong></td><td><strong>自动转接</strong></td><td>去中心化，让对话更自然，Agent 之间配合更像人类同事。</td><td>客户服务系统、多角色扮演游戏。</td></tr><tr><td><strong>McpWorkbench</strong></td><td><strong>USB接口</strong></td><td>拥有海量现成工具库（Github/Slack/Drive等），即插即用。</td><td>需要操作外部软件、读取本地文件的 Agent。</td></tr></tbody></table></div><footer class=post-footer><ul class=post-tags><li><a href=http://ljj1992.fun/tags/autogen/>AutoGen</a></li><li><a href=http://ljj1992.fun/tags/agent/>Agent</a></li><li><a href=http://ljj1992.fun/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/>大模型</a></li><li><a href=http://ljj1992.fun/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81/>工作流</a></li><li><a href=http://ljj1992.fun/tags/worker/>Worker</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://ljj1992.fun/>star徐的博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>